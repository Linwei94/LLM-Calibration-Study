{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0ef28d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_success_failed_indexes(file_path):\n",
    "    \"\"\"\n",
    "    Extract sampled messages where the extracted answer is 'None'.\n",
    "    \"\"\"\n",
    "    # Read the HTML file\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        soup = BeautifulSoup(f, \"html.parser\")\n",
    "\n",
    "    # Find all blocks containing \"Sampled message\"\n",
    "    success = []\n",
    "    failed = []\n",
    "    i = 0\n",
    "    for h3 in soup.find_all(\"h3\"):\n",
    "        if h3.text.strip() == \"Sampled message\":\n",
    "            assistant_div = h3.find_next_sibling(\"div\", class_=\"message assistant\")\n",
    "            results_h3 = assistant_div.find_next_sibling(\"h3\")\n",
    "            # Ensure it's the corresponding \"Results\" section\n",
    "            if results_h3 and results_h3.text.strip() == \"Results\":\n",
    "                # Look for \"Extracted Answer\"\n",
    "                extracted_answer_p = results_h3.find_next_sibling(\"p\", string=lambda t: t and \"Extracted Answer:\" in t)\n",
    "                if extracted_answer_p and (\"None\" in extracted_answer_p.text or \"Z\" in extracted_answer_p.text):\n",
    "                    failed.append(i)\n",
    "            success.append(i)\n",
    "            i = i + 1\n",
    "    # Remove failed indexes from success\n",
    "    success = [i for i in success if i not in failed]\n",
    "                    \n",
    "    return np.array(success), np.array(failed)\n",
    "\n",
    "def get_confidence(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        html_content = file.read()\n",
    "\n",
    "    # Parse the HTML\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "    # Define a regex pattern for \"Extracted Answer Confidence\"\n",
    "    pattern = re.compile(r\"Extracted Answer Confidence:\\s([0-1\\]*\\.?[0-9]+)\")\n",
    "\n",
    "    # Search through the text in the HTML\n",
    "    matches = pattern.findall(soup.get_text())\n",
    "\n",
    "    # Print the extracted confidence values\n",
    "    return np.array(matches, dtype=float)\n",
    "\n",
    "def get_accuracy(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        html_content = file.read()\n",
    "\n",
    "    # Parse the HTML\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "    # Define a regex pattern for \"Extracted Answer Confidence\"\n",
    "    pattern = re.compile(r\"Score:\\s([0-1]*\\.?[0-9]+)\")\n",
    "\n",
    "    # Search through the text in the HTML\n",
    "    matches = pattern.findall(soup.get_text())\n",
    "\n",
    "    # Print the extracted confidence values\n",
    "    return np.array(matches, dtype=float)\n",
    "\n",
    "def get_subject(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        html_content = file.read()\n",
    "\n",
    "    # Parse the HTML\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "    # Define a regex pattern for \"Extracted Answer Confidence\"\n",
    "    pattern = re.compile(r'\\nSubject:\\s(.+)\\n')\n",
    "\n",
    "    # Search through the text in the HTML\n",
    "    matches = pattern.findall(soup.get_text())\n",
    "\n",
    "    # Print the extracted confidence values\n",
    "    return (matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e134feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract confidence of different mode and acc and save to csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def extract_confidence_and_acc(model_name,  linguistic_conf_file_path):\n",
    "    html_filename = \"\"\"../results/mmlu_pro_{model}_{confidence}_shared_sampling_None.html\"\"\"\n",
    "    linguistic_conf = get_confidence(linguistic_conf_file_path)\n",
    "    logits_perp_conf = get_confidence(html_filename.format(model=model_name, confidence=\"logit_perplexity\"))\n",
    "    verbal_num_conf = get_confidence(html_filename.format(model=model_name, confidence=\"verbal_numerical\"))\n",
    "    acc_list = get_accuracy(html_filename.format(model=model_name, confidence=\"verbal_numerical\"))\n",
    "\n",
    "    # get the success and failed indexes\n",
    "    linguistic_success, linguistic_failed = get_success_failed_indexes(linguistic_conf_file_path)\n",
    "    numerical_success, numerical_failed = get_success_failed_indexes(html_filename.format(model=model_name, confidence=\"verbal_numerical\"))\n",
    "    logit_success, logit_failed = get_success_failed_indexes(html_filename.format(model=model_name, confidence=\"logit_perplexity\"))\n",
    "\n",
    "    # turn success and failed indexes to boolean\n",
    "    linguistic_success_bool = np.zeros(linguistic_conf.shape[0], dtype=bool)\n",
    "    linguistic_success_bool[linguistic_success] = 1\n",
    "    logit_success_bool = np.zeros(logits_perp_conf.shape[0], dtype=bool)\n",
    "    logit_success_bool[logit_success] = 1\n",
    "    numerical_success_bool = np.zeros(verbal_num_conf.shape[0], dtype=bool)\n",
    "    numerical_success_bool[numerical_success] = 1\n",
    "\n",
    "    return acc_list, linguistic_conf, logits_perp_conf, verbal_num_conf,\\\n",
    "                        linguistic_success, logit_success, numerical_success,\\\n",
    "                        linguistic_success_bool, logit_success_bool, numerical_success_bool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c06667",
   "metadata": {},
   "source": [
    "## gpt-4.1-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2e9c9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt-4.1-mini\"\n",
    "linguistic_conf_file_path = \"../results/linguistic-judges/mmlu_pro_gpt-4.1-mini_verbal_linguistic_shared_sampling_None_meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8_dec_judge.html\"\n",
    "\n",
    "acc_list, linguistic_conf, logits_perp_conf, verbal_num_conf,\\\n",
    "    linguistic_success, logit_success, numerical_success,\\\n",
    "    linguistic_success_bool, logit_success_bool, numerical_success_bool= \\\n",
    "        extract_confidence_and_acc(model_name, linguistic_conf_file_path)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Linguistic Confidence': linguistic_conf,\n",
    "    'Logit Perplexity Confidence': logits_perp_conf,\n",
    "    'Verbal Numerical Confidence': verbal_num_conf,\n",
    "    'Accuracy': acc_list,\n",
    "    'Linguistic Success': linguistic_success_bool,\n",
    "    'Logit Success': logit_success_bool,\n",
    "    'Numerical Success': numerical_success_bool\n",
    "})\n",
    "\n",
    "df.to_csv(f\"{model_name}_confidence_acc_success\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9507f1ab",
   "metadata": {},
   "source": [
    "## gpt-4.1-nano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a0e4e871",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt-4.1-nano\"\n",
    "linguistic_conf_file_path = \"../results/linguistic-judges/mmlu_pro_gpt-4.1-nano_verbal_linguistic_shared_sampling_None_meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8_dec_judge.html\"\n",
    "\n",
    "acc_list, linguistic_conf, logits_perp_conf, verbal_num_conf,\\\n",
    "    linguistic_success, logit_success, numerical_success,\\\n",
    "    linguistic_success_bool, logit_success_bool, numerical_success_bool= \\\n",
    "        extract_confidence_and_acc(model_name, linguistic_conf_file_path)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Linguistic Confidence': linguistic_conf,\n",
    "    'Logit Perplexity Confidence': logits_perp_conf,\n",
    "    'Verbal Numerical Confidence': verbal_num_conf,\n",
    "    'Accuracy': acc_list,\n",
    "    'Linguistic Success': linguistic_success_bool,\n",
    "    'Logit Success': logit_success_bool,\n",
    "    'Numerical Success': numerical_success_bool\n",
    "})\n",
    "\n",
    "df.to_csv(f\"{model_name}_confidence_acc_success\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf2bac0",
   "metadata": {},
   "source": [
    "## Llama-3.2-3B-Instruct-Turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce172cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Llama-3.2-3B-Instruct-Turbo\"\n",
    "linguistic_conf_file_path = \"../results/linguistic-judges/mmlu_pro_Llama-3.2-3B-Instruct-Turbo_verbal_linguistic_shared_sampling_None_meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8_dec_judge.html\"\n",
    "\n",
    "acc_list, linguistic_conf, logits_perp_conf, verbal_num_conf,\\\n",
    "    linguistic_success, logit_success, numerical_success,\\\n",
    "    linguistic_success_bool, logit_success_bool, numerical_success_bool= \\\n",
    "        extract_confidence_and_acc(model_name, linguistic_conf_file_path)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Linguistic Confidence': linguistic_conf,\n",
    "    'Logit Perplexity Confidence': logits_perp_conf,\n",
    "    'Verbal Numerical Confidence': verbal_num_conf,\n",
    "    'Accuracy': acc_list,\n",
    "    'Linguistic Success': linguistic_success_bool,\n",
    "    'Logit Success': logit_success_bool,\n",
    "    'Numerical Success': numerical_success_bool\n",
    "})\n",
    "\n",
    "df.to_csv(f\"{model_name}_confidence_acc_success\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4d1504",
   "metadata": {},
   "source": [
    "## Meta-Llama-3.1-8B-Instruct-Turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba26d3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Meta-Llama-3.1-8B-Instruct-Turbo\"\n",
    "linguistic_conf_file_path = \"../results/linguistic-judges/mmlu_pro_Meta-Llama-3.1-8B-Instruct-Turbo_verbal_linguistic_shared_sampling_None_meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8_dec_judge.html\"\n",
    "\n",
    "acc_list, linguistic_conf, logits_perp_conf, verbal_num_conf,\\\n",
    "    linguistic_success, logit_success, numerical_success,\\\n",
    "    linguistic_success_bool, logit_success_bool, numerical_success_bool= \\\n",
    "        extract_confidence_and_acc(model_name, linguistic_conf_file_path)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Linguistic Confidence': linguistic_conf,\n",
    "    'Logit Perplexity Confidence': logits_perp_conf,\n",
    "    'Verbal Numerical Confidence': verbal_num_conf,\n",
    "    'Accuracy': acc_list,\n",
    "    'Linguistic Success': linguistic_success_bool,\n",
    "    'Logit Success': logit_success_bool,\n",
    "    'Numerical Success': numerical_success_bool\n",
    "})\n",
    "\n",
    "df.to_csv(f\"{model_name}_confidence_acc_success\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d56809",
   "metadata": {},
   "source": [
    "## Meta-Llama-3.1-70B-Instruct-Turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da92eafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Meta-Llama-3.1-70B-Instruct-Turbo\"\n",
    "linguistic_conf_file_path = \"../results/linguistic-judges/mmlu_pro_Meta-Llama-3.1-70B-Instruct-Turbo_verbal_linguistic_shared_sampling_None_meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8_dec_judge.html\"\n",
    "\n",
    "acc_list, linguistic_conf, logits_perp_conf, verbal_num_conf,\\\n",
    "    linguistic_success, logit_success, numerical_success,\\\n",
    "    linguistic_success_bool, logit_success_bool, numerical_success_bool= \\\n",
    "        extract_confidence_and_acc(model_name, linguistic_conf_file_path)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Linguistic Confidence': linguistic_conf,\n",
    "    'Logit Perplexity Confidence': logits_perp_conf,\n",
    "    'Verbal Numerical Confidence': verbal_num_conf,\n",
    "    'Accuracy': acc_list,\n",
    "    'Linguistic Success': linguistic_success_bool,\n",
    "    'Logit Success': logit_success_bool,\n",
    "    'Numerical Success': numerical_success_bool\n",
    "})\n",
    "\n",
    "df.to_csv(f\"{model_name}_confidence_acc_success\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0fb7f9",
   "metadata": {},
   "source": [
    "## Meta-Llama-3.1-405B-Instruct-Turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "05c525da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Meta-Llama-3.1-405B-Instruct-Turbo\"\n",
    "linguistic_conf_file_path = \"../results/linguistic-judges/mmlu_pro_Meta-Llama-3.1-405B-Instruct-Turbo_verbal_linguistic_shared_sampling_None_Llama-4-Maverick-17B-128E-Instruct-FP8_dec_judge.html\"\n",
    "\n",
    "acc_list, linguistic_conf, logits_perp_conf, verbal_num_conf,\\\n",
    "    linguistic_success, logit_success, numerical_success,\\\n",
    "    linguistic_success_bool, logit_success_bool, numerical_success_bool= \\\n",
    "        extract_confidence_and_acc(model_name, linguistic_conf_file_path)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Linguistic Confidence': linguistic_conf,\n",
    "    'Logit Perplexity Confidence': logits_perp_conf,\n",
    "    'Verbal Numerical Confidence': verbal_num_conf,\n",
    "    'Accuracy': acc_list,\n",
    "    'Linguistic Success': linguistic_success_bool,\n",
    "    'Logit Success': logit_success_bool,\n",
    "    'Numerical Success': numerical_success_bool\n",
    "})\n",
    "\n",
    "df.to_csv(f\"{model_name}_confidence_acc_success\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0797cd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of failed samples for Llama-3.2-3B-Instruct-Turbo: crossfail-80, linguistic-58, logit-61, numerical-79\n",
      "Number of failed samples for Meta-Llama-3.1-8B-Instruct-Turbo: crossfail-467, linguistic-258, logit-310, numerical-411\n",
      "Number of failed samples for Meta-Llama-3.1-70B-Instruct-Turbo: crossfail-112, linguistic-63, logit-67, numerical-111\n",
      "Number of failed samples for Meta-Llama-3.1-405B-Instruct-Turbo: crossfail-77, linguistic-44, logit-47, numerical-75\n",
      "Number of failed samples for gpt-4.1-mini: crossfail-250, linguistic-225, logit-79, numerical-122\n",
      "Number of failed samples for gpt-4.1-nano: crossfail-324, linguistic-126, logit-268, numerical-302\n"
     ]
    }
   ],
   "source": [
    "model_name_lists = [\n",
    "    \"Llama-3.2-3B-Instruct-Turbo\",\n",
    "    \"Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
    "    \"Meta-Llama-3.1-70B-Instruct-Turbo\",\n",
    "    \"Meta-Llama-3.1-405B-Instruct-Turbo\",\n",
    "    \"gpt-4.1-mini\",\n",
    "    \"gpt-4.1-nano\",\n",
    "    ]\n",
    "path_format = \"\"\"../analysis/{model_name}_confidence_acc_success\"\"\"\n",
    "for model_name in model_name_lists:\n",
    "    file_path = path_format.format(model_name=model_name)\n",
    "    df = pd.read_csv(file_path)\n",
    "    # print number of failed samples\n",
    "    print(f\"Number of failed samples for {model_name}: crossfail-{len(df[(df['Linguistic Success'] == 0) | (df['Logit Success'] == 0) | (df['Numerical Success'] == 0)])}, linguistic-{len(df[df['Linguistic Success'] == 0])}, logit-{len(df[df['Logit Success'] == 0])}, numerical-{len(df[df['Numerical Success'] == 0])}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
