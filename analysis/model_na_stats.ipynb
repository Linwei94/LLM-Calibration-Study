{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6101d5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d13d219f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ece(confidences, accuracies, n_bins=10) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the expected calibration error (ECE) given a list of confidence scores (0-1) and accuracy scores (0 or 1).\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({\"conf\": confidences, \"acc\": accuracies}).dropna()\n",
    "\n",
    "    confidences = torch.tensor(df[\"conf\"].tolist())\n",
    "    accuracies = torch.tensor(df[\"acc\"].tolist())\n",
    "    bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
    "    bin_lowers = bin_boundaries[:-1]\n",
    "    bin_uppers = bin_boundaries[1:]\n",
    "\n",
    "    ece = torch.zeros(1)\n",
    "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
    "        # Calculated |confidence - accuracy| in each bin\n",
    "        in_bin = confidences.gt(bin_lower.item()) * confidences.le(bin_upper.item())\n",
    "        prop_in_bin = in_bin.float().mean()\n",
    "        if prop_in_bin.item() > 0:\n",
    "            accuracy_in_bin = accuracies[in_bin].float().mean()\n",
    "            avg_confidence_in_bin = confidences[in_bin].mean()\n",
    "            ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
    "    \n",
    "    return ece.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86d3eb66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12032"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_indices = set()\n",
    "\n",
    "for file in os.listdir(\"../results\"):\n",
    "    if file.endswith(\"csv\"):\n",
    "        df = pd.read_csv(\"../results/\" + file)\n",
    "\n",
    "        # Find indices where either column has NaN\n",
    "        indices_with_nan = df[\n",
    "            df[\"extracted_answer\"].isna() | df[\"verbal_numerical_confidence\"].isna()\n",
    "        ].index\n",
    "\n",
    "        # Combine indices across all files\n",
    "        nan_indices.update(indices_with_nan)\n",
    "\n",
    "# Convert to sorted list if needed\n",
    "nan_indices = sorted(nan_indices)\n",
    "len(nan_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9228210",
   "metadata": {},
   "source": [
    "# Drop NA Across All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "248404fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m      4\u001b[39m         df = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33m../results/\u001b[39m\u001b[33m\"\u001b[39m + file).drop(index=nan_indices).reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      5\u001b[39m         acc_no_na = df\n\u001b[32m      6\u001b[39m         new_row = pd.DataFrame({\n\u001b[32m      7\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mModel\u001b[39m\u001b[33m\"\u001b[39m: [file.replace(\u001b[33m\"\u001b[39m\u001b[33mmmlu_pro_\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m).replace(\u001b[33m\"\u001b[39m\u001b[33m_eval_all_None.csv\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m).strip().capitalize()],\n\u001b[32m      8\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing answer\u001b[39m\u001b[33m\"\u001b[39m: [df[\u001b[33m\"\u001b[39m\u001b[33mextracted_answer\u001b[39m\u001b[33m\"\u001b[39m].isna().sum()],\n\u001b[32m      9\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing verbal numerical confidence\u001b[39m\u001b[33m\"\u001b[39m: [df[\u001b[33m\"\u001b[39m\u001b[33mverbal_numerical_confidence\u001b[39m\u001b[33m\"\u001b[39m].isna().sum()],\n\u001b[32m     10\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing logit perplexity confidence\u001b[39m\u001b[33m\"\u001b[39m: [df[\u001b[33m\"\u001b[39m\u001b[33mlogit_perplexity_confidence\u001b[39m\u001b[33m\"\u001b[39m].isna().sum()],\n\u001b[32m     11\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing verbal linguistic confidence\u001b[39m\u001b[33m\"\u001b[39m: [df[\u001b[33m\"\u001b[39m\u001b[33mverbal_linguistic_confidence\u001b[39m\u001b[33m\"\u001b[39m].isna().sum()],\n\u001b[32m     12\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mAccuracy\u001b[39m\u001b[33m\"\u001b[39m: [(df[\u001b[33m\"\u001b[39m\u001b[33mextracted_answer\u001b[39m\u001b[33m\"\u001b[39m] == df[\u001b[33m\"\u001b[39m\u001b[33mcorrect_answer\u001b[39m\u001b[33m\"\u001b[39m]).mean()],\n\u001b[32m     13\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mAccuracy without na\u001b[39m\u001b[33m\"\u001b[39m: [(acc_no_na[\u001b[33m\"\u001b[39m\u001b[33mextracted_answer\u001b[39m\u001b[33m\"\u001b[39m] == acc_no_na[\u001b[33m\"\u001b[39m\u001b[33mcorrect_answer\u001b[39m\u001b[33m\"\u001b[39m]).mean()],\n\u001b[32m     14\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mECE verbal numerical confidence\u001b[39m\u001b[33m\"\u001b[39m: [calculate_ece(df[\u001b[33m\"\u001b[39m\u001b[33mverbal_numerical_confidence\u001b[39m\u001b[33m\"\u001b[39m].values, (df[\u001b[33m\"\u001b[39m\u001b[33mextracted_answer\u001b[39m\u001b[33m\"\u001b[39m] == df[\u001b[33m\"\u001b[39m\u001b[33mcorrect_answer\u001b[39m\u001b[33m\"\u001b[39m]))],\n\u001b[32m     15\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mECE logit perplexity confidence\u001b[39m\u001b[33m\"\u001b[39m: [calculate_ece(df[\u001b[33m\"\u001b[39m\u001b[33mlogit_perplexity_confidence\u001b[39m\u001b[33m\"\u001b[39m].values, (df[\u001b[33m\"\u001b[39m\u001b[33mextracted_answer\u001b[39m\u001b[33m\"\u001b[39m] == df[\u001b[33m\"\u001b[39m\u001b[33mcorrect_answer\u001b[39m\u001b[33m\"\u001b[39m]))],\n\u001b[32m     16\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mECE verbal linguistic confidence\u001b[39m\u001b[33m\"\u001b[39m: [calculate_ece(df[\u001b[33m\"\u001b[39m\u001b[33mverbal_linguistic_confidence\u001b[39m\u001b[33m\"\u001b[39m].values, (df[\u001b[33m\"\u001b[39m\u001b[33mextracted_answer\u001b[39m\u001b[33m\"\u001b[39m] == df[\u001b[33m\"\u001b[39m\u001b[33mcorrect_answer\u001b[39m\u001b[33m\"\u001b[39m]))],\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mAUROC verbal numerical confidence\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mextracted_answer\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcorrect_answer\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbal_numerical_confidence\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m     18\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mAUROC logit perplexity confidence\u001b[39m\u001b[33m\"\u001b[39m: roc_auc_score((df[\u001b[33m\"\u001b[39m\u001b[33mextracted_answer\u001b[39m\u001b[33m\"\u001b[39m] == df[\u001b[33m\"\u001b[39m\u001b[33mcorrect_answer\u001b[39m\u001b[33m\"\u001b[39m]), df[\u001b[33m\"\u001b[39m\u001b[33mlogit_perplexity_confidence\u001b[39m\u001b[33m\"\u001b[39m].fillna(\u001b[32m0\u001b[39m).values),\n\u001b[32m     19\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mAUROC verbal linguistic confidence\u001b[39m\u001b[33m\"\u001b[39m: roc_auc_score((df[\u001b[33m\"\u001b[39m\u001b[33mextracted_answer\u001b[39m\u001b[33m\"\u001b[39m] == df[\u001b[33m\"\u001b[39m\u001b[33mcorrect_answer\u001b[39m\u001b[33m\"\u001b[39m]), df[\u001b[33m\"\u001b[39m\u001b[33mverbal_linguistic_confidence\u001b[39m\u001b[33m\"\u001b[39m].fillna(\u001b[32m0\u001b[39m).values),\n\u001b[32m     20\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMean verbal numerical confidence\u001b[39m\u001b[33m\"\u001b[39m: [df[\u001b[33m\"\u001b[39m\u001b[33mverbal_numerical_confidence\u001b[39m\u001b[33m\"\u001b[39m].mean()],\n\u001b[32m     21\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMean logit perplexity confidence\u001b[39m\u001b[33m\"\u001b[39m: [df[\u001b[33m\"\u001b[39m\u001b[33mlogit_perplexity_confidence\u001b[39m\u001b[33m\"\u001b[39m].mean()],\n\u001b[32m     22\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMean verbal linguistic confidence\u001b[39m\u001b[33m\"\u001b[39m: [df[\u001b[33m\"\u001b[39m\u001b[33mverbal_linguistic_confidence\u001b[39m\u001b[33m\"\u001b[39m].mean()],\n\u001b[32m     23\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mStd verbal numerical confidence\u001b[39m\u001b[33m\"\u001b[39m: [df[\u001b[33m\"\u001b[39m\u001b[33mverbal_numerical_confidence\u001b[39m\u001b[33m\"\u001b[39m].std()],\n\u001b[32m     24\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mStd logit perplexity confidence\u001b[39m\u001b[33m\"\u001b[39m: [df[\u001b[33m\"\u001b[39m\u001b[33mlogit_perplexity_confidence\u001b[39m\u001b[33m\"\u001b[39m].std()],\n\u001b[32m     25\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mStd verbal linguistic confidence\u001b[39m\u001b[33m\"\u001b[39m: [df[\u001b[33m\"\u001b[39m\u001b[33mverbal_linguistic_confidence\u001b[39m\u001b[33m\"\u001b[39m].std()],\n\u001b[32m     26\u001b[39m         })\n\u001b[32m     27\u001b[39m         stats_df = pd.concat([stats_df, new_row], ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     29\u001b[39m display(stats_df.sort_values(by=\u001b[33m\"\u001b[39m\u001b[33mModel\u001b[39m\u001b[33m\"\u001b[39m, ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm-uncertainty/lib/python3.13/site-packages/sklearn/utils/_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm-uncertainty/lib/python3.13/site-packages/sklearn/metrics/_ranking.py:619\u001b[39m, in \u001b[36mroc_auc_score\u001b[39m\u001b[34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[39m\n\u001b[32m    431\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) \\\u001b[39;00m\n\u001b[32m    432\u001b[39m \u001b[33;03mfrom prediction scores.\u001b[39;00m\n\u001b[32m    433\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    615\u001b[39m \u001b[33;03marray([0.81..., 0.84... , 0.93..., 0.87..., 0.94...])\u001b[39;00m\n\u001b[32m    616\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    618\u001b[39m y_type = type_of_target(y_true, input_name=\u001b[33m\"\u001b[39m\u001b[33my_true\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m619\u001b[39m y_true = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    620\u001b[39m y_score = check_array(y_score, ensure_2d=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y_type == \u001b[33m\"\u001b[39m\u001b[33mmulticlass\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m    623\u001b[39m     y_type == \u001b[33m\"\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y_score.ndim == \u001b[32m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y_score.shape[\u001b[32m1\u001b[39m] > \u001b[32m2\u001b[39m\n\u001b[32m    624\u001b[39m ):\n\u001b[32m    625\u001b[39m     \u001b[38;5;66;03m# do not support partial ROC computation for multiclass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm-uncertainty/lib/python3.13/site-packages/sklearn/utils/validation.py:1130\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1128\u001b[39m     n_samples = _num_samples(array)\n\u001b[32m   1129\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_samples < ensure_min_samples:\n\u001b[32m-> \u001b[39m\u001b[32m1130\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1131\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m) while a\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1132\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1133\u001b[39m             % (n_samples, array.shape, ensure_min_samples, context)\n\u001b[32m   1134\u001b[39m         )\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array.ndim == \u001b[32m2\u001b[39m:\n\u001b[32m   1137\u001b[39m     n_features = array.shape[\u001b[32m1\u001b[39m]\n",
      "\u001b[31mValueError\u001b[39m: Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "stats_df = pd.DataFrame()\n",
    "for file in os.listdir(\"../results\"):\n",
    "    if file.endswith(\"csv\"):\n",
    "        df = pd.read_csv(\"../results/\" + file).drop(index=nan_indices).reset_index(drop=True)\n",
    "        acc_no_na = df\n",
    "        new_row = pd.DataFrame({\n",
    "            \"Model\": [file.replace(\"mmlu_pro_\", \"\").replace(\"_eval_all_None.csv\", \"\").strip().capitalize()],\n",
    "            \"Missing answer\": [df[\"extracted_answer\"].isna().sum()],\n",
    "            \"Missing verbal numerical confidence\": [df[\"verbal_numerical_confidence\"].isna().sum()],\n",
    "            \"Missing logit perplexity confidence\": [df[\"logit_perplexity_confidence\"].isna().sum()],\n",
    "            \"Missing verbal linguistic confidence\": [df[\"verbal_linguistic_confidence\"].isna().sum()],\n",
    "            \"Accuracy\": [(df[\"extracted_answer\"] == df[\"correct_answer\"]).mean()],\n",
    "            \"Accuracy without na\": [(acc_no_na[\"extracted_answer\"] == acc_no_na[\"correct_answer\"]).mean()],\n",
    "            \"ECE verbal numerical confidence\": [calculate_ece(df[\"verbal_numerical_confidence\"].values, (df[\"extracted_answer\"] == df[\"correct_answer\"]))],\n",
    "            \"ECE logit perplexity confidence\": [calculate_ece(df[\"logit_perplexity_confidence\"].values, (df[\"extracted_answer\"] == df[\"correct_answer\"]))],\n",
    "            \"ECE verbal linguistic confidence\": [calculate_ece(df[\"verbal_linguistic_confidence\"].values, (df[\"extracted_answer\"] == df[\"correct_answer\"]))],\n",
    "            \"AUROC verbal numerical confidence\": roc_auc_score((df[\"extracted_answer\"] == df[\"correct_answer\"]).values, df[\"verbal_numerical_confidence\"].fillna(0).values),\n",
    "            \"AUROC logit perplexity confidence\": roc_auc_score((df[\"extracted_answer\"] == df[\"correct_answer\"]), df[\"logit_perplexity_confidence\"].fillna(0).values),\n",
    "            \"AUROC verbal linguistic confidence\": roc_auc_score((df[\"extracted_answer\"] == df[\"correct_answer\"]), df[\"verbal_linguistic_confidence\"].fillna(0).values),\n",
    "            \"Mean verbal numerical confidence\": [df[\"verbal_numerical_confidence\"].mean()],\n",
    "            \"Mean logit perplexity confidence\": [df[\"logit_perplexity_confidence\"].mean()],\n",
    "            \"Mean verbal linguistic confidence\": [df[\"verbal_linguistic_confidence\"].mean()],\n",
    "            \"Std verbal numerical confidence\": [df[\"verbal_numerical_confidence\"].std()],\n",
    "            \"Std logit perplexity confidence\": [df[\"logit_perplexity_confidence\"].std()],\n",
    "            \"Std verbal linguistic confidence\": [df[\"verbal_linguistic_confidence\"].std()],\n",
    "        })\n",
    "        stats_df = pd.concat([stats_df, new_row], ignore_index=True)\n",
    "    \n",
    "display(stats_df.sort_values(by=\"Model\", ignore_index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f91527",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16202836",
   "metadata": {},
   "source": [
    "# Drop NA on an Individual Basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb1af877",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/afs/intern/fangwenhan/miniconda3/envs/llm-uncertainty/lib/python3.13/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/mnt/afs/intern/fangwenhan/miniconda3/envs/llm-uncertainty/lib/python3.13/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/mnt/afs/intern/fangwenhan/miniconda3/envs/llm-uncertainty/lib/python3.13/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Missing answer</th>\n",
       "      <th>Missing verbal numerical confidence</th>\n",
       "      <th>Missing logit perplexity confidence</th>\n",
       "      <th>Missing verbal linguistic confidence</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Accuracy without na</th>\n",
       "      <th>ECE verbal numerical confidence</th>\n",
       "      <th>ECE logit perplexity confidence</th>\n",
       "      <th>ECE verbal linguistic confidence</th>\n",
       "      <th>AUROC verbal numerical confidence</th>\n",
       "      <th>AUROC logit perplexity confidence</th>\n",
       "      <th>AUROC verbal linguistic confidence</th>\n",
       "      <th>Mean verbal numerical confidence</th>\n",
       "      <th>Mean logit perplexity confidence</th>\n",
       "      <th>Mean verbal linguistic confidence</th>\n",
       "      <th>Std verbal numerical confidence</th>\n",
       "      <th>Std logit perplexity confidence</th>\n",
       "      <th>Std verbal linguistic confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gemma-2-27b-it</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.531666</td>\n",
       "      <td>0.532995</td>\n",
       "      <td>0.379636</td>\n",
       "      <td>0.352674</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.612014</td>\n",
       "      <td>0.523690</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.909806</td>\n",
       "      <td>0.884340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.141204</td>\n",
       "      <td>0.046461</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gemma-3-27b-it</td>\n",
       "      <td>12032</td>\n",
       "      <td>12032</td>\n",
       "      <td>12032</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Qwen2.5-7b-instruct</td>\n",
       "      <td>58</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.505402</td>\n",
       "      <td>0.507850</td>\n",
       "      <td>0.390313</td>\n",
       "      <td>0.366994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.642940</td>\n",
       "      <td>0.611824</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.896391</td>\n",
       "      <td>0.872396</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094847</td>\n",
       "      <td>0.054149</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Qwen3-0.6b</td>\n",
       "      <td>2306</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.200299</td>\n",
       "      <td>0.247789</td>\n",
       "      <td>0.691891</td>\n",
       "      <td>0.631562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.546083</td>\n",
       "      <td>0.538223</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.885019</td>\n",
       "      <td>0.831861</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.264321</td>\n",
       "      <td>0.059801</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Qwen3-0.6b-base</td>\n",
       "      <td>3329</td>\n",
       "      <td>2296</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.197224</td>\n",
       "      <td>0.272665</td>\n",
       "      <td>0.736976</td>\n",
       "      <td>0.640971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.605870</td>\n",
       "      <td>0.488874</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.971261</td>\n",
       "      <td>0.838195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.151414</td>\n",
       "      <td>0.081134</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Qwen3-1.7b</td>\n",
       "      <td>264</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.390209</td>\n",
       "      <td>0.398963</td>\n",
       "      <td>0.491705</td>\n",
       "      <td>0.548449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.598064</td>\n",
       "      <td>0.611030</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.875566</td>\n",
       "      <td>0.938659</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.241260</td>\n",
       "      <td>0.029157</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Qwen3-1.7b-think</td>\n",
       "      <td>231</td>\n",
       "      <td>345</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.549618</td>\n",
       "      <td>0.560376</td>\n",
       "      <td>0.326778</td>\n",
       "      <td>0.363263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.724315</td>\n",
       "      <td>0.711066</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.885424</td>\n",
       "      <td>0.912880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.173317</td>\n",
       "      <td>0.028400</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Qwen3-14b</td>\n",
       "      <td>44</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.629322</td>\n",
       "      <td>0.631632</td>\n",
       "      <td>0.267041</td>\n",
       "      <td>0.294918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.706230</td>\n",
       "      <td>0.697831</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.896331</td>\n",
       "      <td>0.924239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109715</td>\n",
       "      <td>0.035738</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Qwen3-14b-base</td>\n",
       "      <td>213</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.581699</td>\n",
       "      <td>0.592182</td>\n",
       "      <td>0.338958</td>\n",
       "      <td>0.282598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.632375</td>\n",
       "      <td>0.581740</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.924956</td>\n",
       "      <td>0.864297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.074858</td>\n",
       "      <td>0.053334</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Qwen3-14b-think</td>\n",
       "      <td>113</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.756566</td>\n",
       "      <td>0.763739</td>\n",
       "      <td>0.129329</td>\n",
       "      <td>0.119671</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.786770</td>\n",
       "      <td>0.748882</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.894385</td>\n",
       "      <td>0.876237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.120138</td>\n",
       "      <td>0.044260</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Qwen3-30b-a3b</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.659159</td>\n",
       "      <td>0.662462</td>\n",
       "      <td>0.265543</td>\n",
       "      <td>0.271912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.733663</td>\n",
       "      <td>0.728696</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.925850</td>\n",
       "      <td>0.931071</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109089</td>\n",
       "      <td>0.034404</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Qwen3-30b-a3b-base</td>\n",
       "      <td>221</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.570396</td>\n",
       "      <td>0.581068</td>\n",
       "      <td>0.343866</td>\n",
       "      <td>0.308058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.634385</td>\n",
       "      <td>0.496692</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.915859</td>\n",
       "      <td>0.878453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.143940</td>\n",
       "      <td>0.072823</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Qwen3-30b-a3b-think</td>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.771775</td>\n",
       "      <td>0.773060</td>\n",
       "      <td>0.122607</td>\n",
       "      <td>0.153267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.811807</td>\n",
       "      <td>0.789704</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.895469</td>\n",
       "      <td>0.925043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.120362</td>\n",
       "      <td>0.030727</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Qwen3-32b</td>\n",
       "      <td>706</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.656167</td>\n",
       "      <td>0.697069</td>\n",
       "      <td>0.220443</td>\n",
       "      <td>0.194539</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.732951</td>\n",
       "      <td>0.612886</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.877494</td>\n",
       "      <td>0.850706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.228535</td>\n",
       "      <td>0.062412</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Qwen3-4b</td>\n",
       "      <td>50</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.527178</td>\n",
       "      <td>0.529377</td>\n",
       "      <td>0.369697</td>\n",
       "      <td>0.420454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693612</td>\n",
       "      <td>0.652720</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.897489</td>\n",
       "      <td>0.947631</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.121436</td>\n",
       "      <td>0.025008</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Qwen3-4b-base</td>\n",
       "      <td>273</td>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.513630</td>\n",
       "      <td>0.525555</td>\n",
       "      <td>0.401186</td>\n",
       "      <td>0.338382</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.655269</td>\n",
       "      <td>0.554263</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.920027</td>\n",
       "      <td>0.852013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129665</td>\n",
       "      <td>0.064456</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Qwen3-4b-think</td>\n",
       "      <td>309</td>\n",
       "      <td>709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.673870</td>\n",
       "      <td>0.691632</td>\n",
       "      <td>0.187993</td>\n",
       "      <td>0.225152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.798604</td>\n",
       "      <td>0.680472</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.887896</td>\n",
       "      <td>0.899022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.131461</td>\n",
       "      <td>0.042445</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Qwen3-8b</td>\n",
       "      <td>41</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.585106</td>\n",
       "      <td>0.587107</td>\n",
       "      <td>0.319753</td>\n",
       "      <td>0.364919</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713786</td>\n",
       "      <td>0.567781</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.906043</td>\n",
       "      <td>0.950025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117109</td>\n",
       "      <td>0.031409</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Qwen3-8b-base</td>\n",
       "      <td>2149</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.456117</td>\n",
       "      <td>0.555297</td>\n",
       "      <td>0.300248</td>\n",
       "      <td>0.427126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.767521</td>\n",
       "      <td>0.395210</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.759224</td>\n",
       "      <td>0.883243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.348216</td>\n",
       "      <td>0.062185</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Qwen3-8b-think</td>\n",
       "      <td>168</td>\n",
       "      <td>312</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.724069</td>\n",
       "      <td>0.734322</td>\n",
       "      <td>0.121647</td>\n",
       "      <td>0.166863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.811526</td>\n",
       "      <td>0.730404</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.858951</td>\n",
       "      <td>0.890932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.145081</td>\n",
       "      <td>0.041105</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Missing answer  Missing verbal numerical confidence  \\\n",
       "0        Gemma-2-27b-it              30                                    0   \n",
       "1        Gemma-3-27b-it           12032                                12032   \n",
       "2   Qwen2.5-7b-instruct              58                                   22   \n",
       "3            Qwen3-0.6b            2306                                   21   \n",
       "4       Qwen3-0.6b-base            3329                                 2296   \n",
       "5            Qwen3-1.7b             264                                   55   \n",
       "6      Qwen3-1.7b-think             231                                  345   \n",
       "7             Qwen3-14b              44                                   14   \n",
       "8        Qwen3-14b-base             213                                  105   \n",
       "9       Qwen3-14b-think             113                                  170   \n",
       "10        Qwen3-30b-a3b              60                                   30   \n",
       "11   Qwen3-30b-a3b-base             221                                   57   \n",
       "12  Qwen3-30b-a3b-think              20                                   27   \n",
       "13            Qwen3-32b             706                                   27   \n",
       "14             Qwen3-4b              50                                   14   \n",
       "15        Qwen3-4b-base             273                                  127   \n",
       "16       Qwen3-4b-think             309                                  709   \n",
       "17             Qwen3-8b              41                                   26   \n",
       "18        Qwen3-8b-base            2149                                   95   \n",
       "19       Qwen3-8b-think             168                                  312   \n",
       "\n",
       "    Missing logit perplexity confidence  Missing verbal linguistic confidence  \\\n",
       "0                                     0                                     0   \n",
       "1                                 12032                                     0   \n",
       "2                                     0                                     0   \n",
       "3                                     0                                     0   \n",
       "4                                     0                                     0   \n",
       "5                                     0                                     0   \n",
       "6                                     0                                     0   \n",
       "7                                     0                                     0   \n",
       "8                                     0                                     0   \n",
       "9                                     0                                     0   \n",
       "10                                    0                                     0   \n",
       "11                                    0                                     0   \n",
       "12                                    0                                     0   \n",
       "13                                    0                                     0   \n",
       "14                                    0                                     0   \n",
       "15                                    0                                     0   \n",
       "16                                    0                                     0   \n",
       "17                                    0                                     0   \n",
       "18                                    0                                     0   \n",
       "19                                    0                                     0   \n",
       "\n",
       "    Accuracy  Accuracy without na  ECE verbal numerical confidence  \\\n",
       "0   0.531666             0.532995                         0.379636   \n",
       "1   0.000000                  NaN                         0.000000   \n",
       "2   0.505402             0.507850                         0.390313   \n",
       "3   0.200299             0.247789                         0.691891   \n",
       "4   0.197224             0.272665                         0.736976   \n",
       "5   0.390209             0.398963                         0.491705   \n",
       "6   0.549618             0.560376                         0.326778   \n",
       "7   0.629322             0.631632                         0.267041   \n",
       "8   0.581699             0.592182                         0.338958   \n",
       "9   0.756566             0.763739                         0.129329   \n",
       "10  0.659159             0.662462                         0.265543   \n",
       "11  0.570396             0.581068                         0.343866   \n",
       "12  0.771775             0.773060                         0.122607   \n",
       "13  0.656167             0.697069                         0.220443   \n",
       "14  0.527178             0.529377                         0.369697   \n",
       "15  0.513630             0.525555                         0.401186   \n",
       "16  0.673870             0.691632                         0.187993   \n",
       "17  0.585106             0.587107                         0.319753   \n",
       "18  0.456117             0.555297                         0.300248   \n",
       "19  0.724069             0.734322                         0.121647   \n",
       "\n",
       "    ECE logit perplexity confidence  ECE verbal linguistic confidence  \\\n",
       "0                          0.352674                               0.0   \n",
       "1                          0.000000                               0.0   \n",
       "2                          0.366994                               0.0   \n",
       "3                          0.631562                               0.0   \n",
       "4                          0.640971                               0.0   \n",
       "5                          0.548449                               0.0   \n",
       "6                          0.363263                               0.0   \n",
       "7                          0.294918                               0.0   \n",
       "8                          0.282598                               0.0   \n",
       "9                          0.119671                               0.0   \n",
       "10                         0.271912                               0.0   \n",
       "11                         0.308058                               0.0   \n",
       "12                         0.153267                               0.0   \n",
       "13                         0.194539                               0.0   \n",
       "14                         0.420454                               0.0   \n",
       "15                         0.338382                               0.0   \n",
       "16                         0.225152                               0.0   \n",
       "17                         0.364919                               0.0   \n",
       "18                         0.427126                               0.0   \n",
       "19                         0.166863                               0.0   \n",
       "\n",
       "    AUROC verbal numerical confidence  AUROC logit perplexity confidence  \\\n",
       "0                            0.612014                           0.523690   \n",
       "1                                 NaN                                NaN   \n",
       "2                            0.642940                           0.611824   \n",
       "3                            0.546083                           0.538223   \n",
       "4                            0.605870                           0.488874   \n",
       "5                            0.598064                           0.611030   \n",
       "6                            0.724315                           0.711066   \n",
       "7                            0.706230                           0.697831   \n",
       "8                            0.632375                           0.581740   \n",
       "9                            0.786770                           0.748882   \n",
       "10                           0.733663                           0.728696   \n",
       "11                           0.634385                           0.496692   \n",
       "12                           0.811807                           0.789704   \n",
       "13                           0.732951                           0.612886   \n",
       "14                           0.693612                           0.652720   \n",
       "15                           0.655269                           0.554263   \n",
       "16                           0.798604                           0.680472   \n",
       "17                           0.713786                           0.567781   \n",
       "18                           0.767521                           0.395210   \n",
       "19                           0.811526                           0.730404   \n",
       "\n",
       "    AUROC verbal linguistic confidence  Mean verbal numerical confidence  \\\n",
       "0                                  0.5                          0.909806   \n",
       "1                                  NaN                               NaN   \n",
       "2                                  0.5                          0.896391   \n",
       "3                                  0.5                          0.885019   \n",
       "4                                  0.5                          0.971261   \n",
       "5                                  0.5                          0.875566   \n",
       "6                                  0.5                          0.885424   \n",
       "7                                  0.5                          0.896331   \n",
       "8                                  0.5                          0.924956   \n",
       "9                                  0.5                          0.894385   \n",
       "10                                 0.5                          0.925850   \n",
       "11                                 0.5                          0.915859   \n",
       "12                                 0.5                          0.895469   \n",
       "13                                 0.5                          0.877494   \n",
       "14                                 0.5                          0.897489   \n",
       "15                                 0.5                          0.920027   \n",
       "16                                 0.5                          0.887896   \n",
       "17                                 0.5                          0.906043   \n",
       "18                                 0.5                          0.759224   \n",
       "19                                 0.5                          0.858951   \n",
       "\n",
       "    Mean logit perplexity confidence  Mean verbal linguistic confidence  \\\n",
       "0                           0.884340                                0.0   \n",
       "1                                NaN                                0.0   \n",
       "2                           0.872396                                0.0   \n",
       "3                           0.831861                                0.0   \n",
       "4                           0.838195                                0.0   \n",
       "5                           0.938659                                0.0   \n",
       "6                           0.912880                                0.0   \n",
       "7                           0.924239                                0.0   \n",
       "8                           0.864297                                0.0   \n",
       "9                           0.876237                                0.0   \n",
       "10                          0.931071                                0.0   \n",
       "11                          0.878453                                0.0   \n",
       "12                          0.925043                                0.0   \n",
       "13                          0.850706                                0.0   \n",
       "14                          0.947631                                0.0   \n",
       "15                          0.852013                                0.0   \n",
       "16                          0.899022                                0.0   \n",
       "17                          0.950025                                0.0   \n",
       "18                          0.883243                                0.0   \n",
       "19                          0.890932                                0.0   \n",
       "\n",
       "    Std verbal numerical confidence  Std logit perplexity confidence  \\\n",
       "0                          0.141204                         0.046461   \n",
       "1                               NaN                              NaN   \n",
       "2                          0.094847                         0.054149   \n",
       "3                          0.264321                         0.059801   \n",
       "4                          0.151414                         0.081134   \n",
       "5                          0.241260                         0.029157   \n",
       "6                          0.173317                         0.028400   \n",
       "7                          0.109715                         0.035738   \n",
       "8                          0.074858                         0.053334   \n",
       "9                          0.120138                         0.044260   \n",
       "10                         0.109089                         0.034404   \n",
       "11                         0.143940                         0.072823   \n",
       "12                         0.120362                         0.030727   \n",
       "13                         0.228535                         0.062412   \n",
       "14                         0.121436                         0.025008   \n",
       "15                         0.129665                         0.064456   \n",
       "16                         0.131461                         0.042445   \n",
       "17                         0.117109                         0.031409   \n",
       "18                         0.348216                         0.062185   \n",
       "19                         0.145081                         0.041105   \n",
       "\n",
       "    Std verbal linguistic confidence  \n",
       "0                                0.0  \n",
       "1                                0.0  \n",
       "2                                0.0  \n",
       "3                                0.0  \n",
       "4                                0.0  \n",
       "5                                0.0  \n",
       "6                                0.0  \n",
       "7                                0.0  \n",
       "8                                0.0  \n",
       "9                                0.0  \n",
       "10                               0.0  \n",
       "11                               0.0  \n",
       "12                               0.0  \n",
       "13                               0.0  \n",
       "14                               0.0  \n",
       "15                               0.0  \n",
       "16                               0.0  \n",
       "17                               0.0  \n",
       "18                               0.0  \n",
       "19                               0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats_df = pd.DataFrame()\n",
    "for file in os.listdir(\"../results\"):\n",
    "    if file.endswith(\"csv\"):\n",
    "        df = pd.read_csv(\"../results/\" + file)\n",
    "        acc_no_na = df[[\"extracted_answer\", \"correct_answer\"]].dropna()\n",
    "        new_row = pd.DataFrame({\n",
    "            \"Model\": [file.replace(\"mmlu_pro_\", \"\").replace(\"_eval_all_None.csv\", \"\").strip().capitalize()],\n",
    "            \"Missing answer\": [df[\"extracted_answer\"].isna().sum()],\n",
    "            \"Missing verbal numerical confidence\": [df[\"verbal_numerical_confidence\"].isna().sum()],\n",
    "            \"Missing logit perplexity confidence\": [df[\"logit_perplexity_confidence\"].isna().sum()],\n",
    "            \"Missing verbal linguistic confidence\": [df[\"verbal_linguistic_confidence\"].isna().sum()],\n",
    "            \"Accuracy\": [(df[\"extracted_answer\"] == df[\"correct_answer\"]).mean()],\n",
    "            \"Accuracy without na\": [(acc_no_na[\"extracted_answer\"] == acc_no_na[\"correct_answer\"]).mean()],\n",
    "            \"ECE verbal numerical confidence\": [calculate_ece(df[\"verbal_numerical_confidence\"].values, (df[\"extracted_answer\"] == df[\"correct_answer\"]))],\n",
    "            \"ECE logit perplexity confidence\": [calculate_ece(df[\"logit_perplexity_confidence\"].values, (df[\"extracted_answer\"] == df[\"correct_answer\"]))],\n",
    "            \"ECE verbal linguistic confidence\": [calculate_ece(df[\"verbal_linguistic_confidence\"].values, (df[\"extracted_answer\"] == df[\"correct_answer\"]))],\n",
    "            \"AUROC verbal numerical confidence\": roc_auc_score((df[\"extracted_answer\"] == df[\"correct_answer\"]).values, df[\"verbal_numerical_confidence\"].fillna(0).values),\n",
    "            \"AUROC logit perplexity confidence\": roc_auc_score((df[\"extracted_answer\"] == df[\"correct_answer\"]), df[\"logit_perplexity_confidence\"].fillna(0).values),\n",
    "            \"AUROC verbal linguistic confidence\": roc_auc_score((df[\"extracted_answer\"] == df[\"correct_answer\"]), df[\"verbal_linguistic_confidence\"].fillna(0).values),\n",
    "            \"Mean verbal numerical confidence\": [df[\"verbal_numerical_confidence\"].mean()],\n",
    "            \"Mean logit perplexity confidence\": [df[\"logit_perplexity_confidence\"].mean()],\n",
    "            \"Mean verbal linguistic confidence\": [df[\"verbal_linguistic_confidence\"].mean()],\n",
    "            \"Std verbal numerical confidence\": [df[\"verbal_numerical_confidence\"].std()],\n",
    "            \"Std logit perplexity confidence\": [df[\"logit_perplexity_confidence\"].std()],\n",
    "            \"Std verbal linguistic confidence\": [df[\"verbal_linguistic_confidence\"].std()],\n",
    "        })\n",
    "        stats_df = pd.concat([stats_df, new_row], ignore_index=True)\n",
    "    \n",
    "display(stats_df.sort_values(by=\"Model\", ignore_index=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-uncertainty",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
