{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6101d5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d13d219f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ece(confidences, accuracies, n_bins=10) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the expected calibration error (ECE) given a list of confidence scores (0-1) and accuracy scores (0 or 1).\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({\"conf\": confidences, \"acc\": accuracies}).dropna()\n",
    "\n",
    "    confidences = torch.tensor(df[\"conf\"].tolist())\n",
    "    accuracies = torch.tensor(df[\"acc\"].tolist())\n",
    "    bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
    "    bin_lowers = bin_boundaries[:-1]\n",
    "    bin_uppers = bin_boundaries[1:]\n",
    "\n",
    "    ece = torch.zeros(1)\n",
    "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
    "        # Calculated |confidence - accuracy| in each bin\n",
    "        in_bin = confidences.gt(bin_lower.item()) * confidences.le(bin_upper.item())\n",
    "        prop_in_bin = in_bin.float().mean()\n",
    "        if prop_in_bin.item() > 0:\n",
    "            accuracy_in_bin = accuracies[in_bin].float().mean()\n",
    "            avg_confidence_in_bin = confidences[in_bin].mean()\n",
    "            ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
    "    \n",
    "    return ece.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16202836",
   "metadata": {},
   "source": [
    "# Drop NA on an Individual Basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb1af877",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_377209/3105310442.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;34m\"Std verbal linguistic confidence\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"verbal_linguistic_confidence\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         })\n\u001b[1;32m     27\u001b[0m         \u001b[0mstats_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstats_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_row\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Model\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/llm-uncertainty/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   7185\u001b[0m             )\n\u001b[1;32m   7186\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7187\u001b[0m             \u001b[0;31m# len(by) == 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7189\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7191\u001b[0m             \u001b[0;31m# need to rewrap column in Series to apply key function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7192\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/llm-uncertainty/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1907\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1908\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1909\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1914\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Model'"
     ]
    }
   ],
   "source": [
    "stats_df = pd.DataFrame()\n",
    "for file in os.listdir(\"../results\"):\n",
    "    if file.endswith(\"csv\"):\n",
    "        df = pd.read_csv(\"../results/\" + file)\n",
    "        acc_no_na = df[[\"extracted_answer\", \"correct_answer\"]].dropna()\n",
    "        new_row = pd.DataFrame({\n",
    "            \"Model\": [file.replace(\"mmlu_pro_\", \"\").replace(\"_eval_all_None.csv\", \"\").strip().capitalize()],\n",
    "            \"Missing answer\": [df[\"extracted_answer\"].isna().sum()],\n",
    "            \"Missing verbal numerical confidence\": [df[\"verbal_numerical_confidence\"].isna().sum()],\n",
    "            \"Missing logit perplexity confidence\": [df[\"logit_perplexity_confidence\"].isna().sum()],\n",
    "            \"Missing verbal linguistic confidence\": [df[\"verbal_linguistic_confidence\"].isna().sum()],\n",
    "            \"Accuracy\": [(df[\"extracted_answer\"] == df[\"correct_answer\"]).mean()],\n",
    "            \"Accuracy without na\": [(acc_no_na[\"extracted_answer\"] == acc_no_na[\"correct_answer\"]).mean()],\n",
    "            \"ECE verbal numerical confidence\": [calculate_ece(df[\"verbal_numerical_confidence\"].values, (df[\"extracted_answer\"] == df[\"correct_answer\"]))],\n",
    "            \"ECE logit perplexity confidence\": [calculate_ece(df[\"logit_perplexity_confidence\"].values, (df[\"extracted_answer\"] == df[\"correct_answer\"]))],\n",
    "            \"ECE verbal linguistic confidence\": [calculate_ece(df[\"verbal_linguistic_confidence\"].values, (df[\"extracted_answer\"] == df[\"correct_answer\"]))],\n",
    "            \"AUROC verbal numerical confidence\": roc_auc_score((df[\"extracted_answer\"] == df[\"correct_answer\"]).values, df[\"verbal_numerical_confidence\"].fillna(0).values),\n",
    "            \"AUROC logit perplexity confidence\": roc_auc_score((df[\"extracted_answer\"] == df[\"correct_answer\"]), df[\"logit_perplexity_confidence\"].fillna(0).values),\n",
    "            \"AUROC verbal linguistic confidence\": roc_auc_score((df[\"extracted_answer\"] == df[\"correct_answer\"]), df[\"verbal_linguistic_confidence\"].fillna(0).values),\n",
    "            \"Mean verbal numerical confidence\": [df[\"verbal_numerical_confidence\"].mean()],\n",
    "            \"Mean logit perplexity confidence\": [df[\"logit_perplexity_confidence\"].mean()],\n",
    "            \"Mean verbal linguistic confidence\": [df[\"verbal_linguistic_confidence\"].mean()],\n",
    "            \"Std verbal numerical confidence\": [df[\"verbal_numerical_confidence\"].std()],\n",
    "            \"Std logit perplexity confidence\": [df[\"logit_perplexity_confidence\"].std()],\n",
    "            \"Std verbal linguistic confidence\": [df[\"verbal_linguistic_confidence\"].std()],\n",
    "        })\n",
    "        stats_df = pd.concat([stats_df, new_row], ignore_index=True)\n",
    "    \n",
    "display(stats_df.sort_values(by=\"Model\", ignore_index=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9228210",
   "metadata": {},
   "source": [
    "# Drop NA Across All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d3eb66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12032"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_indices = set()\n",
    "\n",
    "for file in os.listdir(\"../results\"):\n",
    "    if file.endswith(\"csv\"):\n",
    "        df = pd.read_csv(\"../results/\" + file)\n",
    "\n",
    "        # Find indices where either column has NaN\n",
    "        indices_with_nan = df[\n",
    "            df[\"extracted_answer\"].isna() | df[\"verbal_numerical_confidence\"].isna()\n",
    "        ].index\n",
    "\n",
    "        # Combine indices across all files\n",
    "        nan_indices.update(indices_with_nan)\n",
    "\n",
    "# Convert to sorted list if needed\n",
    "nan_indices = sorted(nan_indices)\n",
    "len(nan_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248404fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m      4\u001b[39m         df = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33m../results/\u001b[39m\u001b[33m\"\u001b[39m + file).drop(index=nan_indices).reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      5\u001b[39m         acc_no_na = df\n\u001b[32m      6\u001b[39m         new_row = pd.DataFrame({\n\u001b[32m      7\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mModel\u001b[39m\u001b[33m\"\u001b[39m: [file.replace(\u001b[33m\"\u001b[39m\u001b[33mmmlu_pro_\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m).replace(\u001b[33m\"\u001b[39m\u001b[33m_eval_all_None.csv\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m).strip().capitalize()],\n\u001b[32m      8\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing answer\u001b[39m\u001b[33m\"\u001b[39m: [df[\u001b[33m\"\u001b[39m\u001b[33mextracted_answer\u001b[39m\u001b[33m\"\u001b[39m].isna().sum()],\n\u001b[32m      9\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing verbal numerical confidence\u001b[39m\u001b[33m\"\u001b[39m: [df[\u001b[33m\"\u001b[39m\u001b[33mverbal_numerical_confidence\u001b[39m\u001b[33m\"\u001b[39m].isna().sum()],\n\u001b[32m     10\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing logit perplexity confidence\u001b[39m\u001b[33m\"\u001b[39m: [df[\u001b[33m\"\u001b[39m\u001b[33mlogit_perplexity_confidence\u001b[39m\u001b[33m\"\u001b[39m].isna().sum()],\n\u001b[32m     11\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing verbal linguistic confidence\u001b[39m\u001b[33m\"\u001b[39m: [df[\u001b[33m\"\u001b[39m\u001b[33mverbal_linguistic_confidence\u001b[39m\u001b[33m\"\u001b[39m].isna().sum()],\n\u001b[32m     12\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mAccuracy\u001b[39m\u001b[33m\"\u001b[39m: [(df[\u001b[33m\"\u001b[39m\u001b[33mextracted_answer\u001b[39m\u001b[33m\"\u001b[39m] == df[\u001b[33m\"\u001b[39m\u001b[33mcorrect_answer\u001b[39m\u001b[33m\"\u001b[39m]).mean()],\n\u001b[32m     13\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mAccuracy without na\u001b[39m\u001b[33m\"\u001b[39m: [(acc_no_na[\u001b[33m\"\u001b[39m\u001b[33mextracted_answer\u001b[39m\u001b[33m\"\u001b[39m] == acc_no_na[\u001b[33m\"\u001b[39m\u001b[33mcorrect_answer\u001b[39m\u001b[33m\"\u001b[39m]).mean()],\n\u001b[32m     14\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mECE verbal numerical confidence\u001b[39m\u001b[33m\"\u001b[39m: [calculate_ece(df[\u001b[33m\"\u001b[39m\u001b[33mverbal_numerical_confidence\u001b[39m\u001b[33m\"\u001b[39m].values, (df[\u001b[33m\"\u001b[39m\u001b[33mextracted_answer\u001b[39m\u001b[33m\"\u001b[39m] == df[\u001b[33m\"\u001b[39m\u001b[33mcorrect_answer\u001b[39m\u001b[33m\"\u001b[39m]))],\n\u001b[32m     15\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mECE logit perplexity confidence\u001b[39m\u001b[33m\"\u001b[39m: [calculate_ece(df[\u001b[33m\"\u001b[39m\u001b[33mlogit_perplexity_confidence\u001b[39m\u001b[33m\"\u001b[39m].values, (df[\u001b[33m\"\u001b[39m\u001b[33mextracted_answer\u001b[39m\u001b[33m\"\u001b[39m] == df[\u001b[33m\"\u001b[39m\u001b[33mcorrect_answer\u001b[39m\u001b[33m\"\u001b[39m]))],\n\u001b[32m     16\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mECE verbal linguistic confidence\u001b[39m\u001b[33m\"\u001b[39m: [calculate_ece(df[\u001b[33m\"\u001b[39m\u001b[33mverbal_linguistic_confidence\u001b[39m\u001b[33m\"\u001b[39m].values, (df[\u001b[33m\"\u001b[39m\u001b[33mextracted_answer\u001b[39m\u001b[33m\"\u001b[39m] == df[\u001b[33m\"\u001b[39m\u001b[33mcorrect_answer\u001b[39m\u001b[33m\"\u001b[39m]))],\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mAUROC verbal numerical confidence\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mextracted_answer\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcorrect_answer\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbal_numerical_confidence\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m     18\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mAUROC logit perplexity confidence\u001b[39m\u001b[33m\"\u001b[39m: roc_auc_score((df[\u001b[33m\"\u001b[39m\u001b[33mextracted_answer\u001b[39m\u001b[33m\"\u001b[39m] == df[\u001b[33m\"\u001b[39m\u001b[33mcorrect_answer\u001b[39m\u001b[33m\"\u001b[39m]), df[\u001b[33m\"\u001b[39m\u001b[33mlogit_perplexity_confidence\u001b[39m\u001b[33m\"\u001b[39m].fillna(\u001b[32m0\u001b[39m).values),\n\u001b[32m     19\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mAUROC verbal linguistic confidence\u001b[39m\u001b[33m\"\u001b[39m: roc_auc_score((df[\u001b[33m\"\u001b[39m\u001b[33mextracted_answer\u001b[39m\u001b[33m\"\u001b[39m] == df[\u001b[33m\"\u001b[39m\u001b[33mcorrect_answer\u001b[39m\u001b[33m\"\u001b[39m]), df[\u001b[33m\"\u001b[39m\u001b[33mverbal_linguistic_confidence\u001b[39m\u001b[33m\"\u001b[39m].fillna(\u001b[32m0\u001b[39m).values),\n\u001b[32m     20\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMean verbal numerical confidence\u001b[39m\u001b[33m\"\u001b[39m: [df[\u001b[33m\"\u001b[39m\u001b[33mverbal_numerical_confidence\u001b[39m\u001b[33m\"\u001b[39m].mean()],\n\u001b[32m     21\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMean logit perplexity confidence\u001b[39m\u001b[33m\"\u001b[39m: [df[\u001b[33m\"\u001b[39m\u001b[33mlogit_perplexity_confidence\u001b[39m\u001b[33m\"\u001b[39m].mean()],\n\u001b[32m     22\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMean verbal linguistic confidence\u001b[39m\u001b[33m\"\u001b[39m: [df[\u001b[33m\"\u001b[39m\u001b[33mverbal_linguistic_confidence\u001b[39m\u001b[33m\"\u001b[39m].mean()],\n\u001b[32m     23\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mStd verbal numerical confidence\u001b[39m\u001b[33m\"\u001b[39m: [df[\u001b[33m\"\u001b[39m\u001b[33mverbal_numerical_confidence\u001b[39m\u001b[33m\"\u001b[39m].std()],\n\u001b[32m     24\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mStd logit perplexity confidence\u001b[39m\u001b[33m\"\u001b[39m: [df[\u001b[33m\"\u001b[39m\u001b[33mlogit_perplexity_confidence\u001b[39m\u001b[33m\"\u001b[39m].std()],\n\u001b[32m     25\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mStd verbal linguistic confidence\u001b[39m\u001b[33m\"\u001b[39m: [df[\u001b[33m\"\u001b[39m\u001b[33mverbal_linguistic_confidence\u001b[39m\u001b[33m\"\u001b[39m].std()],\n\u001b[32m     26\u001b[39m         })\n\u001b[32m     27\u001b[39m         stats_df = pd.concat([stats_df, new_row], ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     29\u001b[39m display(stats_df.sort_values(by=\u001b[33m\"\u001b[39m\u001b[33mModel\u001b[39m\u001b[33m\"\u001b[39m, ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm-uncertainty/lib/python3.13/site-packages/sklearn/utils/_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm-uncertainty/lib/python3.13/site-packages/sklearn/metrics/_ranking.py:619\u001b[39m, in \u001b[36mroc_auc_score\u001b[39m\u001b[34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[39m\n\u001b[32m    431\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) \\\u001b[39;00m\n\u001b[32m    432\u001b[39m \u001b[33;03mfrom prediction scores.\u001b[39;00m\n\u001b[32m    433\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    615\u001b[39m \u001b[33;03marray([0.81..., 0.84... , 0.93..., 0.87..., 0.94...])\u001b[39;00m\n\u001b[32m    616\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    618\u001b[39m y_type = type_of_target(y_true, input_name=\u001b[33m\"\u001b[39m\u001b[33my_true\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m619\u001b[39m y_true = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    620\u001b[39m y_score = check_array(y_score, ensure_2d=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y_type == \u001b[33m\"\u001b[39m\u001b[33mmulticlass\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m    623\u001b[39m     y_type == \u001b[33m\"\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y_score.ndim == \u001b[32m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y_score.shape[\u001b[32m1\u001b[39m] > \u001b[32m2\u001b[39m\n\u001b[32m    624\u001b[39m ):\n\u001b[32m    625\u001b[39m     \u001b[38;5;66;03m# do not support partial ROC computation for multiclass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm-uncertainty/lib/python3.13/site-packages/sklearn/utils/validation.py:1130\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1128\u001b[39m     n_samples = _num_samples(array)\n\u001b[32m   1129\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_samples < ensure_min_samples:\n\u001b[32m-> \u001b[39m\u001b[32m1130\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1131\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m) while a\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1132\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1133\u001b[39m             % (n_samples, array.shape, ensure_min_samples, context)\n\u001b[32m   1134\u001b[39m         )\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array.ndim == \u001b[32m2\u001b[39m:\n\u001b[32m   1137\u001b[39m     n_features = array.shape[\u001b[32m1\u001b[39m]\n",
      "\u001b[31mValueError\u001b[39m: Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "stats_df = pd.DataFrame()\n",
    "for file in os.listdir(\"../results\"):\n",
    "    if file.endswith(\"csv\"):\n",
    "        df = pd.read_csv(\"../results/\" + file).drop(index=nan_indices).reset_index(drop=True)\n",
    "        acc_no_na = df\n",
    "        new_row = pd.DataFrame({\n",
    "            \"Model\": [file.replace(\"mmlu_pro_\", \"\").replace(\"_eval_all_None.csv\", \"\").strip().capitalize()],\n",
    "            \"Missing answer\": [df[\"extracted_answer\"].isna().sum()],\n",
    "            \"Missing verbal numerical confidence\": [df[\"verbal_numerical_confidence\"].isna().sum()],\n",
    "            \"Missing logit perplexity confidence\": [df[\"logit_perplexity_confidence\"].isna().sum()],\n",
    "            \"Missing verbal linguistic confidence\": [df[\"verbal_linguistic_confidence\"].isna().sum()],\n",
    "            \"Accuracy\": [(df[\"extracted_answer\"] == df[\"correct_answer\"]).mean()],\n",
    "            \"Accuracy without na\": [(acc_no_na[\"extracted_answer\"] == acc_no_na[\"correct_answer\"]).mean()],\n",
    "            \"ECE verbal numerical confidence\": [calculate_ece(df[\"verbal_numerical_confidence\"].values, (df[\"extracted_answer\"] == df[\"correct_answer\"]))],\n",
    "            \"ECE logit perplexity confidence\": [calculate_ece(df[\"logit_perplexity_confidence\"].values, (df[\"extracted_answer\"] == df[\"correct_answer\"]))],\n",
    "            \"ECE verbal linguistic confidence\": [calculate_ece(df[\"verbal_linguistic_confidence\"].values, (df[\"extracted_answer\"] == df[\"correct_answer\"]))],\n",
    "            \"AUROC verbal numerical confidence\": roc_auc_score((df[\"extracted_answer\"] == df[\"correct_answer\"]).values, df[\"verbal_numerical_confidence\"].fillna(0).values),\n",
    "            \"AUROC logit perplexity confidence\": roc_auc_score((df[\"extracted_answer\"] == df[\"correct_answer\"]), df[\"logit_perplexity_confidence\"].fillna(0).values),\n",
    "            \"AUROC verbal linguistic confidence\": roc_auc_score((df[\"extracted_answer\"] == df[\"correct_answer\"]), df[\"verbal_linguistic_confidence\"].fillna(0).values),\n",
    "            \"Mean verbal numerical confidence\": [df[\"verbal_numerical_confidence\"].mean()],\n",
    "            \"Mean logit perplexity confidence\": [df[\"logit_perplexity_confidence\"].mean()],\n",
    "            \"Mean verbal linguistic confidence\": [df[\"verbal_linguistic_confidence\"].mean()],\n",
    "            \"Std verbal numerical confidence\": [df[\"verbal_numerical_confidence\"].std()],\n",
    "            \"Std logit perplexity confidence\": [df[\"logit_perplexity_confidence\"].std()],\n",
    "            \"Std verbal linguistic confidence\": [df[\"verbal_linguistic_confidence\"].std()],\n",
    "        })\n",
    "        stats_df = pd.concat([stats_df, new_row], ignore_index=True)\n",
    "    \n",
    "display(stats_df.sort_values(by=\"Model\", ignore_index=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-uncertainty",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
