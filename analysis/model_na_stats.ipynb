{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6101d5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d13d219f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ece(confidences, accuracies, n_bins=10) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the expected calibration error (ECE) given a list of confidence scores (0-1) and accuracy scores (0 or 1).\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({\"conf\": confidences, \"acc\": accuracies}).dropna()\n",
    "\n",
    "    confidences = torch.tensor(df[\"conf\"].tolist())\n",
    "    accuracies = torch.tensor(df[\"acc\"].tolist())\n",
    "    bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
    "    bin_lowers = bin_boundaries[:-1]\n",
    "    bin_uppers = bin_boundaries[1:]\n",
    "\n",
    "    ece = torch.zeros(1)\n",
    "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
    "        # Calculated |confidence - accuracy| in each bin\n",
    "        in_bin = confidences.gt(bin_lower.item()) * confidences.le(bin_upper.item())\n",
    "        prop_in_bin = in_bin.float().mean()\n",
    "        if prop_in_bin.item() > 0:\n",
    "            accuracy_in_bin = accuracies[in_bin].float().mean()\n",
    "            avg_confidence_in_bin = confidences[in_bin].mean()\n",
    "            ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
    "    \n",
    "    return ece.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86d3eb66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4715"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_indices = set()\n",
    "\n",
    "for file in os.listdir(\"../results\"):\n",
    "    if file.endswith(\"csv\"):\n",
    "        df = pd.read_csv(\"../results/\" + file)\n",
    "\n",
    "        # Find indices where either column has NaN\n",
    "        indices_with_nan = df[\n",
    "            df[\"extracted_answer\"].isna() | df[\"verbal_numerical_confidence\"].isna()\n",
    "        ].index\n",
    "\n",
    "        # Combine indices across all files\n",
    "        nan_indices.update(indices_with_nan)\n",
    "\n",
    "# Convert to sorted list if needed\n",
    "nan_indices = sorted(nan_indices)\n",
    "len(nan_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248404fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Missing answer</th>\n",
       "      <th>Missing verbal numerical confidence</th>\n",
       "      <th>Missing logit perplexity confidence</th>\n",
       "      <th>Missing verbal linguistic confidence</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Accuracy without na</th>\n",
       "      <th>ECE verbal numerical confidence</th>\n",
       "      <th>ECE logit perplexity confidence</th>\n",
       "      <th>ECE verbal linguistic confidence</th>\n",
       "      <th>AUROC verbal numerical confidence</th>\n",
       "      <th>AUROC logit perplexity confidence</th>\n",
       "      <th>AUROC verbal linguistic confidence</th>\n",
       "      <th>Mean verbal numerical confidence</th>\n",
       "      <th>Mean logit perplexity confidence</th>\n",
       "      <th>Mean verbal linguistic confidence</th>\n",
       "      <th>Std verbal numerical confidence</th>\n",
       "      <th>Std logit perplexity confidence</th>\n",
       "      <th>Std verbal linguistic confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Claude-3-5-haiku-20241022</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7317</td>\n",
       "      <td>0</td>\n",
       "      <td>0.736641</td>\n",
       "      <td>0.736641</td>\n",
       "      <td>0.174961</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.677942</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.911356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061631</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Claude-3-7-sonnet-20250219</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7317</td>\n",
       "      <td>0</td>\n",
       "      <td>0.875222</td>\n",
       "      <td>0.875222</td>\n",
       "      <td>0.046156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.739587</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.919943</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081832</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Claude-3-haiku-20240307</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7317</td>\n",
       "      <td>0</td>\n",
       "      <td>0.529315</td>\n",
       "      <td>0.529315</td>\n",
       "      <td>0.389709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.521414</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.919024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047096</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deepseek-chat</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.862102</td>\n",
       "      <td>0.862102</td>\n",
       "      <td>0.055658</td>\n",
       "      <td>0.137897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.756998</td>\n",
       "      <td>0.498989</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.917405</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061322</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deepseek-reasoner</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7317</td>\n",
       "      <td>0</td>\n",
       "      <td>0.887386</td>\n",
       "      <td>0.887386</td>\n",
       "      <td>0.033654</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778729</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.920849</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gemini-1.5-flash</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.756321</td>\n",
       "      <td>0.756321</td>\n",
       "      <td>0.198570</td>\n",
       "      <td>0.172543</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.682826</td>\n",
       "      <td>0.698635</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.953443</td>\n",
       "      <td>0.928781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090277</td>\n",
       "      <td>0.046961</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gemini-1.5-flash-8b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.656827</td>\n",
       "      <td>0.656827</td>\n",
       "      <td>0.271525</td>\n",
       "      <td>0.219067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.599284</td>\n",
       "      <td>0.656910</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.926165</td>\n",
       "      <td>0.875893</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105933</td>\n",
       "      <td>0.071131</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gemini-1.5-pro</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.837638</td>\n",
       "      <td>0.837638</td>\n",
       "      <td>0.125566</td>\n",
       "      <td>0.093005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.676164</td>\n",
       "      <td>0.676572</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.962481</td>\n",
       "      <td>0.930643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066883</td>\n",
       "      <td>0.044069</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gemini-2.0-flash</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.852399</td>\n",
       "      <td>0.852399</td>\n",
       "      <td>0.122874</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.719353</td>\n",
       "      <td>0.760090</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.973936</td>\n",
       "      <td>0.869650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065726</td>\n",
       "      <td>0.075660</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gemini-2.0-flash-lite</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.805248</td>\n",
       "      <td>0.805248</td>\n",
       "      <td>0.151665</td>\n",
       "      <td>0.060152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.726906</td>\n",
       "      <td>0.757006</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.955929</td>\n",
       "      <td>0.863708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.092141</td>\n",
       "      <td>0.078199</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Gpt-4.1-mini</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.840782</td>\n",
       "      <td>0.840782</td>\n",
       "      <td>0.100627</td>\n",
       "      <td>0.060768</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.763008</td>\n",
       "      <td>0.750128</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.941409</td>\n",
       "      <td>0.893065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042174</td>\n",
       "      <td>0.048988</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Gpt-4.1-nano</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734727</td>\n",
       "      <td>0.734727</td>\n",
       "      <td>0.158315</td>\n",
       "      <td>0.116574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.706409</td>\n",
       "      <td>0.721518</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.892824</td>\n",
       "      <td>0.851302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.056413</td>\n",
       "      <td>0.057059</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Grok-2-1212</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.834495</td>\n",
       "      <td>0.834495</td>\n",
       "      <td>0.119344</td>\n",
       "      <td>0.089930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.688663</td>\n",
       "      <td>0.663027</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.953374</td>\n",
       "      <td>0.924425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057903</td>\n",
       "      <td>0.036226</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Grok-3-beta</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.858002</td>\n",
       "      <td>0.858002</td>\n",
       "      <td>0.032336</td>\n",
       "      <td>0.079735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.781270</td>\n",
       "      <td>0.734338</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.882916</td>\n",
       "      <td>0.937737</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.079629</td>\n",
       "      <td>0.025750</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Grok-3-mini-beta</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.865109</td>\n",
       "      <td>0.865109</td>\n",
       "      <td>0.070776</td>\n",
       "      <td>0.099540</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.795145</td>\n",
       "      <td>0.674485</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.934751</td>\n",
       "      <td>0.964562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069908</td>\n",
       "      <td>0.018635</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Llama-3.2-3b-instruct-turbo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.388684</td>\n",
       "      <td>0.388684</td>\n",
       "      <td>0.477805</td>\n",
       "      <td>0.416285</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.564075</td>\n",
       "      <td>0.525997</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.865098</td>\n",
       "      <td>0.804969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138828</td>\n",
       "      <td>0.056762</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Llama-4-maverick-17b-128e-instruct-fp8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.856772</td>\n",
       "      <td>0.856772</td>\n",
       "      <td>0.071037</td>\n",
       "      <td>0.085777</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.749004</td>\n",
       "      <td>0.708741</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.927563</td>\n",
       "      <td>0.942549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089963</td>\n",
       "      <td>0.026372</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Llama-4-scout-17b-16e-instruct</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.808118</td>\n",
       "      <td>0.808118</td>\n",
       "      <td>0.133779</td>\n",
       "      <td>0.151279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.727112</td>\n",
       "      <td>0.702513</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.941569</td>\n",
       "      <td>0.959324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.080757</td>\n",
       "      <td>0.022653</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Meta-llama-3.1-405b-instruct-turbo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.825748</td>\n",
       "      <td>0.825748</td>\n",
       "      <td>0.080927</td>\n",
       "      <td>0.049425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.725652</td>\n",
       "      <td>0.665157</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.906224</td>\n",
       "      <td>0.875027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094319</td>\n",
       "      <td>0.044157</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Meta-llama-3.1-70b-instruct-turbo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734317</td>\n",
       "      <td>0.734317</td>\n",
       "      <td>0.176965</td>\n",
       "      <td>0.090294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.623171</td>\n",
       "      <td>0.587349</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.911009</td>\n",
       "      <td>0.824497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088839</td>\n",
       "      <td>0.054020</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Meta-llama-3.1-8b-instruct-turbo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.535875</td>\n",
       "      <td>0.535875</td>\n",
       "      <td>0.284466</td>\n",
       "      <td>0.274763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600351</td>\n",
       "      <td>0.562361</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.819959</td>\n",
       "      <td>0.810638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073049</td>\n",
       "      <td>0.054390</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Qwen3-235b-a22b-fp8-tput</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.830258</td>\n",
       "      <td>0.830258</td>\n",
       "      <td>0.104256</td>\n",
       "      <td>0.091288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.748687</td>\n",
       "      <td>0.728123</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.934022</td>\n",
       "      <td>0.921546</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060723</td>\n",
       "      <td>0.035913</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Qwen3-235b-a22b-fp8-tput-think</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.875222</td>\n",
       "      <td>0.875222</td>\n",
       "      <td>0.028401</td>\n",
       "      <td>0.044870</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.773375</td>\n",
       "      <td>0.755387</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.902142</td>\n",
       "      <td>0.852440</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085316</td>\n",
       "      <td>0.038134</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Model  Missing answer  \\\n",
       "0                Claude-3-5-haiku-20241022               0   \n",
       "1               Claude-3-7-sonnet-20250219               0   \n",
       "2                  Claude-3-haiku-20240307               0   \n",
       "3                            Deepseek-chat               0   \n",
       "4                        Deepseek-reasoner               0   \n",
       "5                         Gemini-1.5-flash               0   \n",
       "6                      Gemini-1.5-flash-8b               0   \n",
       "7                           Gemini-1.5-pro               0   \n",
       "8                         Gemini-2.0-flash               0   \n",
       "9                    Gemini-2.0-flash-lite               0   \n",
       "10                            Gpt-4.1-mini               0   \n",
       "11                            Gpt-4.1-nano               0   \n",
       "12                             Grok-2-1212               0   \n",
       "13                             Grok-3-beta               0   \n",
       "14                        Grok-3-mini-beta               0   \n",
       "15             Llama-3.2-3b-instruct-turbo               0   \n",
       "16  Llama-4-maverick-17b-128e-instruct-fp8               0   \n",
       "17          Llama-4-scout-17b-16e-instruct               0   \n",
       "18      Meta-llama-3.1-405b-instruct-turbo               0   \n",
       "19       Meta-llama-3.1-70b-instruct-turbo               0   \n",
       "20        Meta-llama-3.1-8b-instruct-turbo               0   \n",
       "21                Qwen3-235b-a22b-fp8-tput               0   \n",
       "22          Qwen3-235b-a22b-fp8-tput-think               0   \n",
       "\n",
       "    Missing verbal numerical confidence  Missing logit perplexity confidence  \\\n",
       "0                                     0                                 7317   \n",
       "1                                     0                                 7317   \n",
       "2                                     0                                 7317   \n",
       "3                                     0                                    0   \n",
       "4                                     0                                 7317   \n",
       "5                                     0                                    0   \n",
       "6                                     0                                    0   \n",
       "7                                     0                                    0   \n",
       "8                                     0                                    0   \n",
       "9                                     0                                    0   \n",
       "10                                    0                                    0   \n",
       "11                                    0                                    0   \n",
       "12                                    0                                    0   \n",
       "13                                    0                                    0   \n",
       "14                                    0                                    0   \n",
       "15                                    0                                    0   \n",
       "16                                    0                                    0   \n",
       "17                                    0                                    0   \n",
       "18                                    0                                    0   \n",
       "19                                    0                                    0   \n",
       "20                                    0                                    0   \n",
       "21                                    0                                    0   \n",
       "22                                    0                                    0   \n",
       "\n",
       "    Missing verbal linguistic confidence  Accuracy  Accuracy without na  \\\n",
       "0                                      0  0.736641             0.736641   \n",
       "1                                      0  0.875222             0.875222   \n",
       "2                                      0  0.529315             0.529315   \n",
       "3                                      0  0.862102             0.862102   \n",
       "4                                      0  0.887386             0.887386   \n",
       "5                                      0  0.756321             0.756321   \n",
       "6                                      0  0.656827             0.656827   \n",
       "7                                      0  0.837638             0.837638   \n",
       "8                                      0  0.852399             0.852399   \n",
       "9                                      0  0.805248             0.805248   \n",
       "10                                     0  0.840782             0.840782   \n",
       "11                                     0  0.734727             0.734727   \n",
       "12                                     0  0.834495             0.834495   \n",
       "13                                     0  0.858002             0.858002   \n",
       "14                                     0  0.865109             0.865109   \n",
       "15                                     0  0.388684             0.388684   \n",
       "16                                     0  0.856772             0.856772   \n",
       "17                                     0  0.808118             0.808118   \n",
       "18                                     0  0.825748             0.825748   \n",
       "19                                     0  0.734317             0.734317   \n",
       "20                                     0  0.535875             0.535875   \n",
       "21                                     0  0.830258             0.830258   \n",
       "22                                     0  0.875222             0.875222   \n",
       "\n",
       "    ECE verbal numerical confidence  ECE logit perplexity confidence  \\\n",
       "0                          0.174961                         0.000000   \n",
       "1                          0.046156                         0.000000   \n",
       "2                          0.389709                         0.000000   \n",
       "3                          0.055658                         0.137897   \n",
       "4                          0.033654                         0.000000   \n",
       "5                          0.198570                         0.172543   \n",
       "6                          0.271525                         0.219067   \n",
       "7                          0.125566                         0.093005   \n",
       "8                          0.122874                         0.028569   \n",
       "9                          0.151665                         0.060152   \n",
       "10                         0.100627                         0.060768   \n",
       "11                         0.158315                         0.116574   \n",
       "12                         0.119344                         0.089930   \n",
       "13                         0.032336                         0.079735   \n",
       "14                         0.070776                         0.099540   \n",
       "15                         0.477805                         0.416285   \n",
       "16                         0.071037                         0.085777   \n",
       "17                         0.133779                         0.151279   \n",
       "18                         0.080927                         0.049425   \n",
       "19                         0.176965                         0.090294   \n",
       "20                         0.284466                         0.274763   \n",
       "21                         0.104256                         0.091288   \n",
       "22                         0.028401                         0.044870   \n",
       "\n",
       "    ECE verbal linguistic confidence  AUROC verbal numerical confidence  \\\n",
       "0                                0.0                           0.677942   \n",
       "1                                0.0                           0.739587   \n",
       "2                                0.0                           0.521414   \n",
       "3                                0.0                           0.756998   \n",
       "4                                0.0                           0.778729   \n",
       "5                                0.0                           0.682826   \n",
       "6                                0.0                           0.599284   \n",
       "7                                0.0                           0.676164   \n",
       "8                                0.0                           0.719353   \n",
       "9                                0.0                           0.726906   \n",
       "10                               0.0                           0.763008   \n",
       "11                               0.0                           0.706409   \n",
       "12                               0.0                           0.688663   \n",
       "13                               0.0                           0.781270   \n",
       "14                               0.0                           0.795145   \n",
       "15                               0.0                           0.564075   \n",
       "16                               0.0                           0.749004   \n",
       "17                               0.0                           0.727112   \n",
       "18                               0.0                           0.725652   \n",
       "19                               0.0                           0.623171   \n",
       "20                               0.0                           0.600351   \n",
       "21                               0.0                           0.748687   \n",
       "22                               0.0                           0.773375   \n",
       "\n",
       "    AUROC logit perplexity confidence  AUROC verbal linguistic confidence  \\\n",
       "0                            0.500000                                 0.5   \n",
       "1                            0.500000                                 0.5   \n",
       "2                            0.500000                                 0.5   \n",
       "3                            0.498989                                 0.5   \n",
       "4                            0.500000                                 0.5   \n",
       "5                            0.698635                                 0.5   \n",
       "6                            0.656910                                 0.5   \n",
       "7                            0.676572                                 0.5   \n",
       "8                            0.760090                                 0.5   \n",
       "9                            0.757006                                 0.5   \n",
       "10                           0.750128                                 0.5   \n",
       "11                           0.721518                                 0.5   \n",
       "12                           0.663027                                 0.5   \n",
       "13                           0.734338                                 0.5   \n",
       "14                           0.674485                                 0.5   \n",
       "15                           0.525997                                 0.5   \n",
       "16                           0.708741                                 0.5   \n",
       "17                           0.702513                                 0.5   \n",
       "18                           0.665157                                 0.5   \n",
       "19                           0.587349                                 0.5   \n",
       "20                           0.562361                                 0.5   \n",
       "21                           0.728123                                 0.5   \n",
       "22                           0.755387                                 0.5   \n",
       "\n",
       "    Mean verbal numerical confidence  Mean logit perplexity confidence  \\\n",
       "0                           0.911356                               NaN   \n",
       "1                           0.919943                               NaN   \n",
       "2                           0.919024                               NaN   \n",
       "3                           0.917405                          0.999998   \n",
       "4                           0.920849                               NaN   \n",
       "5                           0.953443                          0.928781   \n",
       "6                           0.926165                          0.875893   \n",
       "7                           0.962481                          0.930643   \n",
       "8                           0.973936                          0.869650   \n",
       "9                           0.955929                          0.863708   \n",
       "10                          0.941409                          0.893065   \n",
       "11                          0.892824                          0.851302   \n",
       "12                          0.953374                          0.924425   \n",
       "13                          0.882916                          0.937737   \n",
       "14                          0.934751                          0.964562   \n",
       "15                          0.865098                          0.804969   \n",
       "16                          0.927563                          0.942549   \n",
       "17                          0.941569                          0.959324   \n",
       "18                          0.906224                          0.875027   \n",
       "19                          0.911009                          0.824497   \n",
       "20                          0.819959                          0.810638   \n",
       "21                          0.934022                          0.921546   \n",
       "22                          0.902142                          0.852440   \n",
       "\n",
       "    Mean verbal linguistic confidence  Std verbal numerical confidence  \\\n",
       "0                                 0.0                         0.061631   \n",
       "1                                 0.0                         0.081832   \n",
       "2                                 0.0                         0.047096   \n",
       "3                                 0.0                         0.061322   \n",
       "4                                 0.0                         0.078725   \n",
       "5                                 0.0                         0.090277   \n",
       "6                                 0.0                         0.105933   \n",
       "7                                 0.0                         0.066883   \n",
       "8                                 0.0                         0.065726   \n",
       "9                                 0.0                         0.092141   \n",
       "10                                0.0                         0.042174   \n",
       "11                                0.0                         0.056413   \n",
       "12                                0.0                         0.057903   \n",
       "13                                0.0                         0.079629   \n",
       "14                                0.0                         0.069908   \n",
       "15                                0.0                         0.138828   \n",
       "16                                0.0                         0.089963   \n",
       "17                                0.0                         0.080757   \n",
       "18                                0.0                         0.094319   \n",
       "19                                0.0                         0.088839   \n",
       "20                                0.0                         0.073049   \n",
       "21                                0.0                         0.060723   \n",
       "22                                0.0                         0.085316   \n",
       "\n",
       "    Std logit perplexity confidence  Std verbal linguistic confidence  \n",
       "0                               NaN                               0.0  \n",
       "1                               NaN                               0.0  \n",
       "2                               NaN                               0.0  \n",
       "3                          0.000070                               0.0  \n",
       "4                               NaN                               0.0  \n",
       "5                          0.046961                               0.0  \n",
       "6                          0.071131                               0.0  \n",
       "7                          0.044069                               0.0  \n",
       "8                          0.075660                               0.0  \n",
       "9                          0.078199                               0.0  \n",
       "10                         0.048988                               0.0  \n",
       "11                         0.057059                               0.0  \n",
       "12                         0.036226                               0.0  \n",
       "13                         0.025750                               0.0  \n",
       "14                         0.018635                               0.0  \n",
       "15                         0.056762                               0.0  \n",
       "16                         0.026372                               0.0  \n",
       "17                         0.022653                               0.0  \n",
       "18                         0.044157                               0.0  \n",
       "19                         0.054020                               0.0  \n",
       "20                         0.054390                               0.0  \n",
       "21                         0.035913                               0.0  \n",
       "22                         0.038134                               0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats_df = pd.DataFrame()\n",
    "for file in os.listdir(\"../results\"):\n",
    "    if file.endswith(\"csv\"):\n",
    "        df = pd.read_csv(\"../results/\" + file).drop(index=nan_indices).reset_index(drop=True)\n",
    "        # df_no_na = df[[\"extracted_answer\", \"correct_answer\", \"verbal_numerical_confidence\", \"logit_perplexity_confidence\", \"verbal_linguistic_confidence\"]].dropna()\n",
    "        # acc_no_na = df[[\"extracted_answer\", \"correct_answer\"]].dropna()\n",
    "        acc_no_na = df\n",
    "        new_row = pd.DataFrame({\n",
    "            \"Model\": [file.replace(\"mmlu_pro_\", \"\").replace(\"_eval_all_None.csv\", \"\").strip().capitalize()],\n",
    "            \"Missing answer\": [df[\"extracted_answer\"].isna().sum()],\n",
    "            \"Missing verbal numerical confidence\": [df[\"verbal_numerical_confidence\"].isna().sum()],\n",
    "            \"Missing logit perplexity confidence\": [df[\"logit_perplexity_confidence\"].isna().sum()],\n",
    "            \"Missing verbal linguistic confidence\": [df[\"verbal_linguistic_confidence\"].isna().sum()],\n",
    "            \"Accuracy\": [(df[\"extracted_answer\"] == df[\"correct_answer\"]).mean()],\n",
    "            \"Accuracy without na\": [(acc_no_na[\"extracted_answer\"] == acc_no_na[\"correct_answer\"]).mean()],\n",
    "            \"ECE verbal numerical confidence\": [calculate_ece(df[\"verbal_numerical_confidence\"].values, (df[\"extracted_answer\"] == df[\"correct_answer\"]))],\n",
    "            \"ECE logit perplexity confidence\": [calculate_ece(df[\"logit_perplexity_confidence\"].values, (df[\"extracted_answer\"] == df[\"correct_answer\"]))],\n",
    "            \"ECE verbal linguistic confidence\": [calculate_ece(df[\"verbal_linguistic_confidence\"].values, (df[\"extracted_answer\"] == df[\"correct_answer\"]))],\n",
    "            \"AUROC verbal numerical confidence\": roc_auc_score((df[\"extracted_answer\"] == df[\"correct_answer\"]).values, df[\"verbal_numerical_confidence\"].fillna(0).values),\n",
    "            \"AUROC logit perplexity confidence\": roc_auc_score((df[\"extracted_answer\"] == df[\"correct_answer\"]), df[\"logit_perplexity_confidence\"].fillna(0).values),\n",
    "            \"AUROC verbal linguistic confidence\": roc_auc_score((df[\"extracted_answer\"] == df[\"correct_answer\"]), df[\"verbal_linguistic_confidence\"].fillna(0).values),\n",
    "            \"Mean verbal numerical confidence\": [df[\"verbal_numerical_confidence\"].mean()],\n",
    "            \"Mean logit perplexity confidence\": [df[\"logit_perplexity_confidence\"].mean()],\n",
    "            \"Mean verbal linguistic confidence\": [df[\"verbal_linguistic_confidence\"].mean()],\n",
    "            \"Std verbal numerical confidence\": [df[\"verbal_numerical_confidence\"].std()],\n",
    "            \"Std logit perplexity confidence\": [df[\"logit_perplexity_confidence\"].std()],\n",
    "            \"Std verbal linguistic confidence\": [df[\"verbal_linguistic_confidence\"].std()],\n",
    "        })\n",
    "        stats_df = pd.concat([stats_df, new_row], ignore_index=True)\n",
    "    \n",
    "display(stats_df.sort_values(by=\"Model\", ignore_index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1af877",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-uncertainty",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
