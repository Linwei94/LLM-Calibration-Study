{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd725025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34e3828e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"cache_multi_generation\"\n",
    "files = os.listdir(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18b31c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTILINGUAL_ANSWER_REGEXES = [\n",
    "    r\"Answer\\s*:\",\n",
    "    r\"Answer\\s*:​​​​​​\",  # Korean invisible character\n",
    "    r\"উত্তর\\s*:\",\n",
    "    r\"उत्तर\\s*:\",\n",
    "    r\"উত্তরঃ\",\n",
    "    r\"উত্তর\\s*:\",\n",
    "    r\"Antwort\\s*:\",\n",
    "    r\"답변\\s*:\",\n",
    "    r\"정답\\s*:\",\n",
    "    r\"답\\s*:\",\n",
    "    r\"答案\\s*：\",\n",
    "    r\"答案\\s*:\",\n",
    "    r\"答\\s*：\",\n",
    "    r\"答\\s*:\",\n",
    "    r\"答复\\s*：\",\n",
    "    r\"答曰\\s*：\",\n",
    "    r\"الإجابة:\",\n",
    "    r\"الجواب:\",\n",
    "    r\"إجابة:\",\n",
    "    r\"الإجابة النهائية:\",\n",
    "    r\"الإجابة الصحيحة:\",\n",
    "    r\"الإجابة الصحيحة هي:\",\n",
    "    r\"الإجابة هي:\",\n",
    "    r\"الجواب النهائي:\",\n",
    "    r\"Respuesta\\s*:\",\n",
    "    r\"Risposta\\s*:\",\n",
    "    r\"答え\\s*:\",\n",
    "    r\"答え\\s*：\",\n",
    "    r\"回答\\s*:\",\n",
    "    r\"回答\\s*：\",\n",
    "    r\"解答\\s*:\",\n",
    "    r\"Jawaban\\s*:\",\n",
    "    r\"Réponse\\s*:\",\n",
    "    r\"Resposta\\s*:\",\n",
    "    r\"Jibu\\s*:\",\n",
    "    r\"Idahun\\s*:\",\n",
    "    r\"Ìdáhùn\\s*:\",\n",
    "    r\"Idáhùn\\s*:\",\n",
    "    r\"Àmọ̀nà\\s*:\",\n",
    "    r\"Àdáhùn\\s*:\",\n",
    "    r\"Ànúgọ\\s*:\",\n",
    "    r\"Àṣàyàn\\s*:\",\n",
    "]\n",
    "\n",
    "MULTILINGUAL_ANSWER_PATTERN_TEMPLATE = (\n",
    "    \"(?i){}[ \\t]*([A-D]|[أ-د]|[অ]|[ব]|[ড]|[ঢ]|[Ａ]|[Ｂ]|[Ｃ]|[Ｄ])\"\n",
    ")\n",
    "\n",
    "def normalize_response(response: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize the response by removing markdown and LaTeX formatting that may prevent a match.\n",
    "    \"\"\"\n",
    "    if response:\n",
    "        return (\n",
    "            response.replace(\"**\", \"\")\n",
    "            .replace(\"$\\\\boxed{\", \"\")\n",
    "            .replace(\"}$\", \"\")\n",
    "            .replace(\"\\\\$\", \"\")\n",
    "            .replace(\"$\\\\text{\", \"\")\n",
    "            .replace(\"$\", \"\")\n",
    "            .replace(\"\\\\mathrm{\", \"\")\n",
    "            .replace(\"\\\\{\", \"\")\n",
    "            .replace(\"\\\\text\", \"\")\n",
    "            .replace(\"\\\\(\", \"\")\n",
    "            .replace(\"\\\\mathbf{\", \"\")\n",
    "            .replace(\"{\", \"\")\n",
    "            .replace(\"\\\\boxed\", \"\")\n",
    "        )\n",
    "    return \"\"\n",
    "\n",
    "def normalize_extracted_answer(extracted_answer: str) -> str:\n",
    "    return (\n",
    "        # In arabic these are the letters used for A-D in multiple choice questions\n",
    "        extracted_answer.replace(\"أ\", \" A\")\n",
    "        .replace(\"ب\", \" B\")\n",
    "        .replace(\"ج\", \" C\")\n",
    "        .replace(\"د\", \" D\")\n",
    "        # In Bengali these are the letters used for A-D in multiple choice questions\n",
    "        .replace(\"অ\", \" A\")\n",
    "        .replace(\"ব\", \" B\")\n",
    "        .replace(\"ড\", \" C\")\n",
    "        .replace(\"ঢ\", \" D\")\n",
    "        # In Japanese these are the letters sometimes used for A-D in multiple choice questions\n",
    "        .replace(\"Ａ\", \" A\")\n",
    "        .replace(\"Ｂ\", \" B\")\n",
    "        .replace(\"Ｃ\", \" C\")\n",
    "        .replace(\"Ｄ\", \" D\")\n",
    "        .strip()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7090c33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_answer(response_text: str):\n",
    "    response_text = normalize_response(response_text)\n",
    "    answer_patterns = [\n",
    "        r\"[Aa]nswer:?[\\s]*[\\n]*([A-J])\",   \n",
    "        r\"[Aa]nswer:[\\s]*[\\n]*\\(?([A-J])\\)?\", \n",
    "        r\"[Aa]nswer:[\\s]*[\\n]*\\[?([A-J])\\]?\",  \n",
    "        r\"[Aa]nswer:[\\s]*[\\n]*([A-J])[,)]\",         \n",
    "        r\"[Aa]nswer:[\\s]*[\\n]*([A-J])\\s*,?.*\",\n",
    "        r\"Answer:\\n([A-J])\\nConfidence\",         \n",
    "        r\"answer is\\s*\\[?\\(?([A-J])\\]?\\)?\",   \n",
    "        r\"answer should be\\s*\\[?\\(?([A-J])\\]?\\)?\",   \n",
    "        r\"best option is \\(?([A-J])\\)?\",\n",
    "        r\"best match is option \\(?([A-J])\\)?\",\n",
    "        r\"the closest is \\(?([A-J])\\)?\",\n",
    "        r\"Answer:\\n*^([A-J])$\",\n",
    "        r\"^([A-J])$\"\n",
    "    ]\n",
    "    # max_search_scope = len(response_text.splitlines())\n",
    "    # for end in range(3, max_search_scope, 10):\n",
    "    search_scope =  \"\\n\".join(response_text.splitlines()[::-1])\n",
    "    extracted_answer = None\n",
    "    # Default answer extracrion from Simple Evals\n",
    "    for answer_regex in MULTILINGUAL_ANSWER_REGEXES:\n",
    "        regex = MULTILINGUAL_ANSWER_PATTERN_TEMPLATE.format(answer_regex)\n",
    "        match = re.search(regex, search_scope)\n",
    "        if match:\n",
    "            extracted_answer = normalize_extracted_answer(match.group(1)).strip()\n",
    "            if extracted_answer in \"ABCDEFGHIJ\":\n",
    "                return extracted_answer\n",
    "    # More complex extraction regex\n",
    "    for pattern in answer_patterns:\n",
    "        match = re.search(pattern, search_scope, re.IGNORECASE)\n",
    "        if match:\n",
    "            extracted_answer = normalize_extracted_answer(match.group(1)).strip()\n",
    "            if extracted_answer in \"ABCDEFGHIJ\":\n",
    "                return extracted_answer\n",
    "        match = re.search(pattern, search_scope, re.MULTILINE)\n",
    "        if match:\n",
    "            extracted_answer = normalize_extracted_answer(match.group(1)).strip()\n",
    "            if extracted_answer in \"ABCDEFGHIJ\":\n",
    "                return extracted_answer\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e54cf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_response(lst):\n",
    "    return [extract_answer(r) for r in lst]\n",
    "\n",
    "def process_multi_responses(lst):\n",
    "    return [[extract_answer(r) for r in r_ls] for r_ls in lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9c6c6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ece(confidences, accuracies, n_bins=10) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the expected calibration error (ECE) given a list of confidence scores (0-1) and accuracy scores (0 or 1).\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({\"conf\": confidences, \"acc\": accuracies}).dropna()\n",
    "\n",
    "    if len(df) == 0:\n",
    "        return None\n",
    "\n",
    "    confidences = torch.tensor(df[\"conf\"].tolist())\n",
    "    accuracies = torch.tensor(df[\"acc\"].tolist())\n",
    "    bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
    "    bin_lowers = bin_boundaries[:-1]\n",
    "    bin_uppers = bin_boundaries[1:]\n",
    "\n",
    "    ece = torch.zeros(1)\n",
    "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
    "        # Calculated |confidence - accuracy| in each bin\n",
    "        in_bin = confidences.gt(bin_lower.item()) * confidences.le(bin_upper.item())\n",
    "        prop_in_bin = in_bin.float().mean()\n",
    "        if prop_in_bin.item() > 0:\n",
    "            accuracy_in_bin = accuracies[in_bin].float().mean()\n",
    "            avg_confidence_in_bin = confidences[in_bin].mean()\n",
    "            ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
    "    \n",
    "    return ece.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d7a6a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_adaptive_ece(confidences, accuracies, n_bins=10) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the Adaptive Expected Calibration Error (AECE) using equal-frequency binning.\n",
    "    \"\"\"\n",
    "    # Ensure inputs are torch tensors\n",
    "\n",
    "    df = pd.DataFrame({\"conf\": confidences, \"acc\": accuracies}).dropna()\n",
    "\n",
    "    confidences = df[\"conf\"].tolist()\n",
    "    accuracies = df[\"acc\"].tolist()\n",
    "\n",
    "    if len(df) == 0:\n",
    "        return None\n",
    "\n",
    "    confidences = torch.tensor(confidences, dtype=torch.float)\n",
    "    accuracies = torch.tensor(accuracies, dtype=torch.float)\n",
    "\n",
    "    # Compute bin boundaries (equal number of samples per bin)\n",
    "    sorted_conf = np.sort(confidences.detach().cpu().numpy())\n",
    "    bin_boundaries = np.interp(\n",
    "        np.linspace(0, len(sorted_conf), n_bins + 1),\n",
    "        np.arange(len(sorted_conf)),\n",
    "        sorted_conf\n",
    "    )\n",
    "    bin_lowers = bin_boundaries[:-1]\n",
    "    bin_uppers = bin_boundaries[1:]\n",
    "\n",
    "    adaptive_ece = torch.zeros(1)\n",
    "\n",
    "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
    "        in_bin = (confidences > bin_lower) * (confidences <= bin_upper)\n",
    "        prop_in_bin = in_bin.float().mean()\n",
    "\n",
    "        if prop_in_bin.item() > 0:\n",
    "            accuracy_in_bin = accuracies[in_bin].mean()\n",
    "            avg_confidence_in_bin = confidences[in_bin].mean()\n",
    "            # Ensure both are torch tensors\n",
    "            diff = torch.abs(avg_confidence_in_bin - accuracy_in_bin)\n",
    "            adaptive_ece += diff * prop_in_bin\n",
    "\n",
    "    return adaptive_ece.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a14a8629",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_roc_auc_score(acc, conf):\n",
    "    try:\n",
    "        return roc_auc_score(acc, conf)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "594942d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcq_majority_vote(answer_list: list[str]) -> tuple[str, float]:\n",
    "    answer_list = [a for a in answer_list if a is not None]\n",
    "\n",
    "    counter = Counter(answer_list)\n",
    "    majority_answer, weight = counter.most_common(1)[0]\n",
    "\n",
    "    weight /= len(answer_list)\n",
    "    return majority_answer, weight\n",
    "\n",
    "\n",
    "def mcq_consistency_confidence(first_answer: str, answer_list: list[str]) -> tuple[str, float]:\n",
    "    answer_list = [a for a in answer_list if a != None]\n",
    "    consistent_answers = [a for a in answer_list if a == first_answer]\n",
    "    try:\n",
    "        return len(consistent_answers) / len(answer_list)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f3fd280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file in files:\n",
    "#     if file in os.listdir(\"cache\"):\n",
    "#         print(dir + \"/\" + file)\n",
    "#         with open(dir + \"/\" + file, 'rb') as f:\n",
    "#             multi = pickle.load(f)\n",
    "#         with open(\"cache/\" + file, \"rb\") as f:\n",
    "#             single = pickle.load(f)\n",
    "#         prompt_messages = [eg[\"prompt_messages\"] for eg in multi]\n",
    "#         correct_answer = [eg[\"answer\"] for eg in multi]\n",
    "#         multi_responses = [eg[\"rep_responses\"] for eg in multi]\n",
    "#         multi_logprobs = [eg[\"rep_logprobs\"] for eg in multi]\n",
    "#         single_response = [eg[\"response\"] for eg in single]\n",
    "#         single_logprobs = [eg[\"logprobs\"] for eg in single]\n",
    "#         df  = pd.DataFrame({\n",
    "#             \"prompt_messages\": prompt_messages,\n",
    "#             \"correct_answer\": correct_answer,\n",
    "#             \"single_answer\": process_single_response(single_response),\n",
    "#             \"multi_answers\": process_multi_responses(multi_responses),\n",
    "#             \"multi_responses\": multi_responses,\n",
    "#             \"multi_logprobs\": multi_logprobs,\n",
    "#             \"single_response\": single_response,\n",
    "#             \"single_logprobs\": single_logprobs\n",
    "#         })\n",
    "#         df[[\"majority_answer\", \"majority_confidence\"]] = df[\"multi_answers\"].apply(\n",
    "#             lambda x: pd.Series(mcq_majority_vote(x))\n",
    "#         )\n",
    "#         df[\"majority_accuracy\"] = df[\"majority_answer\"] == df[\"correct_answer\"]\n",
    "#         df[\"consistency_accuracy\"] = df[\"single_answer\"] == df[\"correct_answer\"]\n",
    "#         df[\"consistency_confidence\"] = df.apply(\n",
    "#             lambda row: mcq_consistency_confidence(row[\"single_answer\"], row[\"multi_answers\"]),\n",
    "#             axis=1\n",
    "#         )\n",
    "#         display(df)\n",
    "#         df.to_csv(\"semantic_results/\" + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfd1dcb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>consistency_accuracy</th>\n",
       "      <th>consistency_ece</th>\n",
       "      <th>consistency_adaptive_ece</th>\n",
       "      <th>consistency_auroc</th>\n",
       "      <th>majority_accuracy</th>\n",
       "      <th>majority_ece</th>\n",
       "      <th>majority_adaptive_ece</th>\n",
       "      <th>majority_auroc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Qwen3-0.6b-fp8</td>\n",
       "      <td>0.249428</td>\n",
       "      <td>0.059555</td>\n",
       "      <td>0.061301</td>\n",
       "      <td>0.480235</td>\n",
       "      <td>0.105221</td>\n",
       "      <td>0.213441</td>\n",
       "      <td>0.213408</td>\n",
       "      <td>0.496421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Qwen3-1.7b-fp8</td>\n",
       "      <td>0.394645</td>\n",
       "      <td>0.146359</td>\n",
       "      <td>0.146359</td>\n",
       "      <td>0.477865</td>\n",
       "      <td>0.102770</td>\n",
       "      <td>0.193971</td>\n",
       "      <td>0.166944</td>\n",
       "      <td>0.503190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Qwen3-14b-fp8</td>\n",
       "      <td>0.630063</td>\n",
       "      <td>0.302095</td>\n",
       "      <td>0.301975</td>\n",
       "      <td>0.485103</td>\n",
       "      <td>0.104551</td>\n",
       "      <td>0.178286</td>\n",
       "      <td>0.178236</td>\n",
       "      <td>0.513541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Qwen3-4b-fp8</td>\n",
       "      <td>0.529604</td>\n",
       "      <td>0.239227</td>\n",
       "      <td>0.238712</td>\n",
       "      <td>0.487927</td>\n",
       "      <td>0.107277</td>\n",
       "      <td>0.181949</td>\n",
       "      <td>0.181932</td>\n",
       "      <td>0.512127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Qwen3-8b-fp8</td>\n",
       "      <td>0.587291</td>\n",
       "      <td>0.275618</td>\n",
       "      <td>0.275518</td>\n",
       "      <td>0.491108</td>\n",
       "      <td>0.104849</td>\n",
       "      <td>0.181751</td>\n",
       "      <td>0.181701</td>\n",
       "      <td>0.506273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model  consistency_accuracy  consistency_ece  \\\n",
       "3  Qwen3-0.6b-fp8              0.249428         0.059555   \n",
       "2  Qwen3-1.7b-fp8              0.394645         0.146359   \n",
       "1   Qwen3-14b-fp8              0.630063         0.302095   \n",
       "0    Qwen3-4b-fp8              0.529604         0.239227   \n",
       "4    Qwen3-8b-fp8              0.587291         0.275618   \n",
       "\n",
       "   consistency_adaptive_ece  consistency_auroc  majority_accuracy  \\\n",
       "3                  0.061301           0.480235           0.105221   \n",
       "2                  0.146359           0.477865           0.102770   \n",
       "1                  0.301975           0.485103           0.104551   \n",
       "0                  0.238712           0.487927           0.107277   \n",
       "4                  0.275518           0.491108           0.104849   \n",
       "\n",
       "   majority_ece  majority_adaptive_ece  majority_auroc  \n",
       "3      0.213441               0.213408        0.496421  \n",
       "2      0.193971               0.166944        0.503190  \n",
       "1      0.178286               0.178236        0.513541  \n",
       "0      0.181949               0.181932        0.512127  \n",
       "4      0.181751               0.181701        0.506273  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_df = pd.DataFrame()\n",
    "for file in os.listdir(\"semantic_results\"):\n",
    "    df = pd.read_csv(\"semantic_results/\" + file)\n",
    "    df = df.dropna()\n",
    "    row = pd.DataFrame({\n",
    "        \"model\": [file.replace(\"mmlu_pro_shared_sampling_\", \"\").replace(\"_full_0\", \"\").strip().capitalize()],\n",
    "        \n",
    "        \"consistency_accuracy\": df[\"consistency_accuracy\"].mean(),\n",
    "        \"consistency_ece\": calculate_ece(df[\"consistency_confidence\"], df[\"consistency_accuracy\"]),\n",
    "        \"consistency_adaptive_ece\": calculate_adaptive_ece(df[\"consistency_confidence\"], df[\"consistency_accuracy\"]),\n",
    "        \"consistency_auroc\": safe_roc_auc_score(df[\"consistency_accuracy\"], df[\"consistency_confidence\"]),\n",
    "\n",
    "        \"majority_accuracy\": df[\"majority_accuracy\"].mean(),\n",
    "        \"majority_ece\": calculate_ece(df[\"majority_confidence\"], df[\"majority_accuracy\"]),\n",
    "        \"majority_adaptive_ece\": calculate_adaptive_ece(df[\"majority_confidence\"], df[\"majority_accuracy\"]),\n",
    "        \"majority_auroc\": safe_roc_auc_score(df[\"majority_accuracy\"], df[\"majority_confidence\"]),\n",
    "    })\n",
    "    semantic_df = pd.concat([semantic_df, row], ignore_index=True)\n",
    "semantic_df.sort_values(by=\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb48ed9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-uncertainty",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
